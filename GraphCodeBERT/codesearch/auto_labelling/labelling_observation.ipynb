{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def remove_docstrings(code):\n",
    "    # 使用正则表达式匹配被 \"\"\" 包括的部分，并替换为空字符串\n",
    "    cleaned_code = re.sub(r'\"\"\".*?\"\"\"', '', code, flags=re.DOTALL)\n",
    "    cleaned_code = re.sub(r\"'''.*?'''\", '', cleaned_code, flags=re.DOTALL)\n",
    "    return cleaned_code\n",
    "\n",
    "def cosine_similarity_matrix(nl_features, code_features):\n",
    "    # 计算每个特征向量的范数\n",
    "    nl_norms = np.linalg.norm(nl_features, axis=1, keepdims=True)\n",
    "    code_norms = np.linalg.norm(code_features, axis=1, keepdims=True)\n",
    "    \n",
    "    # 计算点积\n",
    "    dot_product = np.dot(nl_features, code_features.T)\n",
    "    \n",
    "    # 计算余弦相似度矩阵\n",
    "    cosine_similarity = dot_product / (nl_norms * code_norms.T)\n",
    "    \n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_padding_intervals(tokenized_id_data):\n",
    "    \"\"\"\n",
    "    移除 tokenized_id_data 中所有 `[0,0]` 区间（除非它是开头的第一个区间）。\n",
    "\n",
    "    Args:\n",
    "    - tokenized_id_data (list of lists): 包含区间的列表，每个区间是一个长度为 2 的列表。\n",
    "\n",
    "    Returns:\n",
    "    - filtered_data (list of lists): 移除 `[0,0]` 填充数据后的区间列表。\n",
    "    \"\"\"\n",
    "    if isinstance(tokenized_id_data, np.ndarray):\n",
    "        tokenized_id_data = tokenized_id_data.tolist()  # 将 NumPy 数组转换为列表\n",
    "    # 处理的结果列表\n",
    "    filtered_data = []\n",
    "\n",
    "    # 保留开头的 `[0,0]` 区间（如果存在）\n",
    "    if tokenized_id_data and tokenized_id_data[0] == [0,0]:\n",
    "        filtered_data.append([0,0])\n",
    "        start_index = 1  # 从第二个元素开始检查\n",
    "    else:\n",
    "        start_index = 0\n",
    "\n",
    "    # 处理剩余的区间\n",
    "    for interval in tokenized_id_data[start_index:]:\n",
    "        if interval != [0,0]:  # 仅添加非 `[0,0]` 区间\n",
    "            filtered_data.append(interval)\n",
    "\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def load_loss_data(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/yiming/cophi/projects/fork/CodeBERT/GraphCodeBERT/codesearch/auto_labelling/train.jsonl\", \"r\") as f:\n",
    "    train_dataset = [json.loads(line) for line in f.readlines()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# 文件路径\n",
    "json_file_path = '/home/yiming/cophi/projects/fork/CodeBERT/GraphCodeBERT/codesearch/auto_labelling/tokenized_code_tokens_train.json'\n",
    "\n",
    "# 读取JSON文件\n",
    "with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "    code_tokens_data = json.load(f)\n",
    "\n",
    "# 文件路径\n",
    "json_file_path = '/home/yiming/cophi/projects/fork/CodeBERT/GraphCodeBERT/codesearch/auto_labelling/tokenized_comment_tokens_train.json'\n",
    "\n",
    "\n",
    "# 读取JSON文件\n",
    "with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "    nl_tokens_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预设10种高对比度颜色\n",
    "high_contrast_colors = [\n",
    "    \"#FF0000\", \"#00FF00\", \"#0000FF\", \"#FF00FF\", \"#00FFFF\",\n",
    "    \"#800000\", \"#008000\", \"#000080\", \"#808080\", \"#FFA500\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "input_path = \"/home/yiming/cophi/projects/fork/CodeBERT/GraphCodeBERT/codesearch/auto_labelling/auto_label_unique.jsonl\"\n",
    "idx_list = []\n",
    "match_list = []\n",
    "\n",
    "with open(input_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        line = line.strip().rstrip(',')  # 去除行末的逗号\n",
    "        json_obj = json.loads(line)\n",
    "        idx_list.append(json_obj['idx'])\n",
    "        match_list.append(json_obj['match'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corresponding values in match_list: [[[0, 2], [13, 31]], [[4, 4, 6, 6], [10, 10, 33, 36]]]\n",
      "Comment indices list: [[0, 1, 2], [4, 6]]\n",
      "Code indices list: [[13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], [10, 33, 34, 35, 36]]\n"
     ]
    }
   ],
   "source": [
    "# 提取match_list中对应索引的值\n",
    "match_values = match_list[indice]\n",
    "\n",
    "# 输出结果\n",
    "print(\"Corresponding values in match_list:\", match_values)\n",
    "# 初始化结果列表\n",
    "comment_list = []\n",
    "code_list = []\n",
    "\n",
    "# 遍历 match_values，处理每个 comment 和 code 的区间\n",
    "for match in match_values:  # 假设 match_values 的结构是 [[...]]\n",
    "    comment_intervals, code_intervals = match\n",
    "\n",
    "    # 展开 comment 的所有索引\n",
    "    comment_indices = []\n",
    "    for start, end in zip(comment_intervals[::2], comment_intervals[1::2]):\n",
    "        comment_indices.extend(range(start, end + 1))\n",
    "    comment_list.append(comment_indices)\n",
    "\n",
    "    # 展开 code 的所有索引\n",
    "    code_indices = []\n",
    "    for start, end in zip(code_intervals[::2], code_intervals[1::2]):\n",
    "        code_indices.extend(range(start, end + 1))\n",
    "    code_list.append(code_indices)\n",
    "\n",
    "# 输出结果\n",
    "print(\"Comment indices list:\", comment_list)\n",
    "print(\"Code indices list:\", code_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import deque\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "token_list1 = nl_tokens_data[idx_list[indice]][1:]\n",
    "doc_snippet = train_dataset[idx_list[indice]][\"docstring\"]\n",
    "# 将 token 与对应的贡献值配对，并去掉 token 中的 \"Ġ\" 符号\n",
    "tokens_with_contributions = deque([(token.replace(\"Ġ\", \"\"), 1.0) for token in token_list1])\n",
    "\n",
    "# 为每个 comment_list 的索引组指定颜色\n",
    "color_map = {}\n",
    "for i, indices in enumerate(comment_list):\n",
    "    color = high_contrast_colors[i % len(high_contrast_colors)]  # 循环使用颜色\n",
    "    for idx in indices:\n",
    "        color_map[idx] = color\n",
    "\n",
    "# 生成HTML带字体大小和颜色调整的输出\n",
    "html_string = \"<pre>\"\n",
    "buffer = \"\"\n",
    "current_index = 0  # 追踪 code_snippet 中字符的索引位置\n",
    "\n",
    "# 遍历原始代码片段的每个字符\n",
    "for char in doc_snippet:\n",
    "    if char == \"\\n\":\n",
    "        # 遇到换行符则添加 <br> 标签并清空缓冲区\n",
    "        html_string += buffer + \"<br>\"\n",
    "        buffer = \"\"\n",
    "    elif tokens_with_contributions:\n",
    "        # 获取当前 token 和其贡献值\n",
    "        token, _ = tokens_with_contributions[0]\n",
    "        buffer += char\n",
    "\n",
    "        # 逐字符匹配：检查 token 是否与 buffer 逐字符匹配\n",
    "        if buffer == token:\n",
    "            color = color_map.get(current_index, \"black\")  # 如果索引有颜色则应用，否则默认为黑色\n",
    "            html_string += f'<span style=\"color: {color};\">{buffer}</span>'\n",
    "            buffer = \"\"  # 清空缓冲区\n",
    "            tokens_with_contributions.popleft()  # 移除已匹配的 token\n",
    "            current_index += 1\n",
    "        elif not token.startswith(buffer):\n",
    "            # 如果缓冲区字符序列和当前 token 不匹配，将缓冲区第一个字符添加到 HTML 并继续逐字符匹配\n",
    "            color = color_map.get(current_index, \"black\")\n",
    "            html_string += f'<span style=\"color: {color};\">{buffer[0]}</span>'\n",
    "            buffer = buffer[1:]      \n",
    "        \n",
    "    else:\n",
    "        # 如果没有更多 token 需要匹配，默认输出字符\n",
    "        color = color_map.get(current_index, \"black\")\n",
    "        html_string += f'<span style=\"color: {color};\">{char}</span>'\n",
    "\n",
    "html_string += buffer  # 添加剩余的缓冲区内容\n",
    "html_string += \"</pre>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre><span style=\"color: #FF0000;\">Return</span><span style=\"color: #FF0000;\"> </span><span style=\"color: #FF0000;\">att</span><span style=\"color: #FF0000;\">rs</span><span style=\"color: black;\"> </span><span style=\"color: black;\">with</span><span style=\"color: #00FF00;\"> </span><span style=\"color: #00FF00;\">keys</span><span style=\"color: black;\"> </span><span style=\"color: black;\">in</span><span style=\"color: #00FF00;\"> </span><span style=\"color: #00FF00;\">keys</span><span style=\"color: black;\"> </span><span style=\"color: black;\">list</span></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre><span style=\"color: black;\">def</span><span style=\"color: black;\"> </span><span style=\"color: black;\">_</span><span style=\"color: black;\">pick</span><span style=\"color: black;\">_</span><span style=\"color: black;\">att</span><span style=\"color: black;\">rs</span><span style=\"color: black;\">(</span><span style=\"color: black;\">att</span><span style=\"color: black;\">rs</span><span style=\"color: black;\">,</span><span style=\"color: #00FF00;\"> </span><span style=\"color: #00FF00;\">keys</span><span style=\"color: black;\">)</span><span style=\"color: black;\">:</span><br><span style=\"color: #FF0000;\"> </span><span style=\"color: #FF0000;\"> </span><span style=\"color: #FF0000;\"> </span><span style=\"color: #FF0000;\"> </span><br><span style=\"color: #FF0000;\"> </span><span style=\"color: #FF0000;\"> </span><span style=\"color: #FF0000;\"> </span><span style=\"color: #FF0000;\"> </span><span style=\"color: #FF0000;\">return</span><span style=\"color: #FF0000;\"> </span><span style=\"color: #FF0000;\">dict</span><span style=\"color: #FF0000;\">(</span><span style=\"color: #FF0000;\">(</span><span style=\"color: #FF0000;\">k</span><span style=\"color: #FF0000;\">,</span><span style=\"color: #FF0000;\"> </span><span style=\"color: #FF0000;\">v</span><span style=\"color: #FF0000;\">)</span><span style=\"color: #FF0000;\"> </span><span style=\"color: #FF0000;\">for</span><span style=\"color: #FF0000;\"> </span><span style=\"color: #FF0000;\">k</span><span style=\"color: #FF0000;\">,</span><span style=\"color: #FF0000;\"> </span><span style=\"color: #FF0000;\">v</span><span style=\"color: #FF0000;\"> </span><span style=\"color: #FF0000;\">in</span><span style=\"color: #FF0000;\"> </span><span style=\"color: #FF0000;\">att</span><span style=\"color: #FF0000;\">rs</span><span style=\"color: #FF0000;\">.</span><span style=\"color: #FF0000;\">items</span><span style=\"color: #FF0000;\">(</span><span style=\"color: #FF0000;\">)</span><span style=\"color: black;\"> </span><span style=\"color: black;\">if</span><span style=\"color: #00FF00;\"> </span><span style=\"color: #00FF00;\">k</span><span style=\"color: #00FF00;\"> </span><span style=\"color: #00FF00;\">in</span><span style=\"color: #00FF00;\"> </span><span style=\"color: #00FF00;\">keys</span><span style=\"color: #00FF00;\">)</span></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 假设我们有原始代码片段和分词后的 tokens（包含缩进和换行）\n",
    "code_snippet = remove_docstrings(train_dataset[idx_list[indice]][\"code\"])\n",
    "token_list2 = code_tokens_data[idx_list[indice]][1:]\n",
    "\n",
    "\n",
    "# 将 token 与对应的贡献值配对，并去掉 token 中的 \"Ġ\" 符号\n",
    "tokens_with_contributions = deque([(token.replace(\"Ġ\", \"\"), 1.0) for token in token_list2])\n",
    "\n",
    "# 为每个 code_list 的索引组指定颜色\n",
    "color_map = {}\n",
    "for i, indices in enumerate(code_list):\n",
    "    color = high_contrast_colors[i % len(high_contrast_colors)]  # 循环使用颜色\n",
    "    for idx in indices:\n",
    "        color_map[idx] = color\n",
    "\n",
    "# 生成HTML带颜色调整的输出\n",
    "formatted_output = \"<pre>\"\n",
    "buffer = \"\"\n",
    "current_index = 0  # 追踪 code_snippet 中字符的索引位置\n",
    "\n",
    "# 遍历原始代码片段的每个字符\n",
    "for char in code_snippet:\n",
    "    if char == \"\\n\":\n",
    "        # 遇到换行符则添加 <br> 标签并清空缓冲区\n",
    "        formatted_output += buffer + \"<br>\"\n",
    "        buffer = \"\"\n",
    "    elif tokens_with_contributions:\n",
    "        # 获取当前 token 和其贡献值\n",
    "        token, _ = tokens_with_contributions[0]\n",
    "            \n",
    "        buffer += char\n",
    "\n",
    "        # 逐字符匹配：检查 token 是否与 buffer 逐字符匹配\n",
    "        if buffer == token:\n",
    "            color = color_map.get(current_index, \"black\")  # 如果索引有颜色则应用，否则默认为黑色\n",
    "            formatted_output += f'<span style=\"color: {color};\">{buffer}</span>'\n",
    "            buffer = \"\"  # 清空缓冲区\n",
    "            tokens_with_contributions.popleft()  # 移除已匹配的 token\n",
    "            current_index += 1\n",
    "        elif not token.startswith(buffer):\n",
    "            # 如果缓冲区字符序列和当前 token 不匹配，将缓冲区第一个字符添加到 HTML 并继续逐字符匹配\n",
    "            color = color_map.get(current_index, \"black\")\n",
    "            formatted_output += f'<span style=\"color: {color};\">{buffer[0]}</span>'\n",
    "            buffer = buffer[1:]      \n",
    "        \n",
    "    else:\n",
    "        # 如果没有更多 token 需要匹配，默认输出字符\n",
    "        color = color_map.get(current_index, \"black\")\n",
    "        formatted_output += f'<span style=\"color: {color};\">{char}</span>'\n",
    "\n",
    "formatted_output += buffer  # 添加剩余的缓冲区内容\n",
    "formatted_output += \"</pre>\"\n",
    "\n",
    "# 在Jupyter Notebook中显示带有字体大小和颜色调整的文本\n",
    "display(HTML(html_string))\n",
    "# 在Jupyter Notebook中显示带有颜色调整的文本\n",
    "display(HTML(formatted_output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
