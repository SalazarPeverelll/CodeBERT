{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yiming/anaconda3/envs/visualizer/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from umap.umap_ import find_ab_params\n",
    "\n",
    "from singleVis.custom_weighted_random_sampler import CustomWeightedRandomSampler\n",
    "from singleVis.SingleVisualizationModel import VisModel\n",
    "from singleVis.losses import ReconstructionLoss, TemporalLoss, SingleVisLoss, DummyTemporalLoss\n",
    "from singleVis.backend import convert_distance_to_probability, compute_cross_entropy\n",
    "from singleVis.edge_dataset import VisDataHandler\n",
    "from singleVis.trainer import BaseTextTrainer\n",
    "from singleVis.eval.evaluator import Evaluator\n",
    "from singleVis.data import NormalDataProvider\n",
    "from singleVis.spatial_edge_constructor import SingleEpochTextSpatialEdgeConstructor\n",
    "\n",
    "from singleVis.projector import VISProjector\n",
    "from singleVis.utils import find_neighbor_preserving_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "class UmapLoss(nn.Module):\n",
    "    def __init__(self, negative_sample_rate, device, _a=1.0, _b=1.0, repulsion_strength=1.0):\n",
    "        super(UmapLoss, self).__init__()\n",
    "\n",
    "        self._negative_sample_rate = negative_sample_rate\n",
    "        self._a = _a,\n",
    "        self._b = _b,\n",
    "        self._repulsion_strength = repulsion_strength\n",
    "        self.DEVICE = torch.device(device)\n",
    "\n",
    "    @property\n",
    "    def a(self):\n",
    "        return self._a[0]\n",
    "\n",
    "    @property\n",
    "    def b(self):\n",
    "        return self._b[0]\n",
    "\n",
    "    def forward(self, embedding_to, embedding_from, probs):\n",
    "        # get negative samples\n",
    "        batch_size = embedding_to.shape[0]\n",
    "        embedding_neg_to = torch.repeat_interleave(embedding_to, self._negative_sample_rate, dim=0)\n",
    "        repeat_neg = torch.repeat_interleave(embedding_from, self._negative_sample_rate, dim=0)\n",
    "        randperm = torch.randperm(repeat_neg.shape[0])\n",
    "        embedding_neg_from = repeat_neg[randperm]\n",
    "        neg_num = len(embedding_neg_from)\n",
    "\n",
    "        positive_distance = torch.norm(embedding_to - embedding_from, dim=1)\n",
    "        negative_distance = torch.norm(embedding_neg_to - embedding_neg_from, dim=1)\n",
    "\n",
    "        distance_embedding = torch.cat(\n",
    "            (\n",
    "                positive_distance,\n",
    "                negative_distance,\n",
    "            ),\n",
    "            dim=0,\n",
    "        )\n",
    "        probabilities_distance = convert_distance_to_probability(\n",
    "            distance_embedding, self.a, self.b\n",
    "        )\n",
    "        probabilities_distance = probabilities_distance.to(self.DEVICE)\n",
    "\n",
    "        probabilities_graph = torch.cat(\n",
    "            (torch.ones(batch_size).to(self.DEVICE), torch.zeros(neg_num).to(self.DEVICE)), dim=0,\n",
    "        )\n",
    "\n",
    "        # probabilities_graph = torch.cat(\n",
    "        #     (probs.to(self.DEVICE), torch.zeros(neg_num).to(self.DEVICE)), dim=0,\n",
    "        # )\n",
    "\n",
    "        probabilities_graph = probabilities_graph.to(device=self.DEVICE)\n",
    "\n",
    "        # compute cross entropy\n",
    "        (_, _, ce_loss) = compute_cross_entropy(\n",
    "            probabilities_graph,\n",
    "            probabilities_distance,\n",
    "            repulsion_strength=self._repulsion_strength,\n",
    "        )   \n",
    "\n",
    "        return torch.mean(ce_loss)\n",
    "\n",
    "class DVILoss(nn.Module):\n",
    "    def __init__(self, umap_loss, recon_loss, temporal_loss, lambd1, lambd2, device):\n",
    "        super(DVILoss, self).__init__()\n",
    "        self.umap_loss = umap_loss\n",
    "        self.recon_loss = recon_loss\n",
    "        self.temporal_loss = temporal_loss\n",
    "        self.lambd1 = lambd1\n",
    "        self.lambd2 = lambd2\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, edge_to, edge_from, a_to, a_from, curr_model,probs):\n",
    "      \n",
    "        outputs = curr_model( edge_to, edge_from)\n",
    "        embedding_to, embedding_from = outputs[\"umap\"]\n",
    "        recon_to, recon_from = outputs[\"recon\"]\n",
    "\n",
    "        recon_l = self.recon_loss(edge_to, edge_from, recon_to, recon_from, a_to, a_from).to(self.device)\n",
    "        umap_l = self.umap_loss(embedding_to, embedding_from, probs)\n",
    "        temporal_l = self.temporal_loss(curr_model).to(self.device)\n",
    "\n",
    "        loss = umap_l + self.lambd1 * recon_l + self.lambd2 * temporal_l\n",
    "\n",
    "        return umap_l, umap_l, self.lambd1 *recon_l, self.lambd2 *temporal_l, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def remove_docstrings(code):\n",
    "    # 使用正则表达式匹配被 \"\"\" 包括的部分，并替换为空字符串\n",
    "    cleaned_code = re.sub(r'\"\"\".*?\"\"\"', '', code, flags=re.DOTALL)\n",
    "    cleaned_code = re.sub(r\"'''.*?'''\", '', cleaned_code, flags=re.DOTALL)\n",
    "    return cleaned_code\n",
    "\n",
    "def cosine_similarity_matrix(nl_features, code_features):\n",
    "    # 计算每个特征向量的范数\n",
    "    nl_norms = np.linalg.norm(nl_features, axis=1, keepdims=True)\n",
    "    code_norms = np.linalg.norm(code_features, axis=1, keepdims=True)\n",
    "    \n",
    "    # 计算点积\n",
    "    dot_product = np.dot(nl_features, code_features.T)\n",
    "    \n",
    "    # 计算余弦相似度矩阵\n",
    "    cosine_similarity = dot_product / (nl_norms * code_norms.T)\n",
    "    \n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_padding_intervals(tokenized_id_data):\n",
    "    \"\"\"\n",
    "    移除 tokenized_id_data 中所有 `[0,0]` 区间（除非它是开头的第一个区间）。\n",
    "\n",
    "    Args:\n",
    "    - tokenized_id_data (list of lists): 包含区间的列表，每个区间是一个长度为 2 的列表。\n",
    "\n",
    "    Returns:\n",
    "    - filtered_data (list of lists): 移除 `[0,0]` 填充数据后的区间列表。\n",
    "    \"\"\"\n",
    "    if isinstance(tokenized_id_data, np.ndarray):\n",
    "        tokenized_id_data = tokenized_id_data.tolist()  # 将 NumPy 数组转换为列表\n",
    "    # 处理的结果列表\n",
    "    filtered_data = []\n",
    "\n",
    "    # 保留开头的 `[0,0]` 区间（如果存在）\n",
    "    if tokenized_id_data and tokenized_id_data[0] == [0,0]:\n",
    "        filtered_data.append([0,0])\n",
    "        start_index = 1  # 从第二个元素开始检查\n",
    "    else:\n",
    "        start_index = 0\n",
    "\n",
    "    # 处理剩余的区间\n",
    "    for interval in tokenized_id_data[start_index:]:\n",
    "        if interval != [0,0]:  # 仅添加非 `[0,0]` 区间\n",
    "            filtered_data.append(interval)\n",
    "\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def load_loss_data(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "valid_code_path = \"/home/yiming/cophi/projects/fork/CoSQA_Plus/datasetBuild/dataset/gpt4o_augment_codebase_process.json\"\n",
    "code_dataset = []\n",
    "with open(valid_code_path, \"r\") as f:\n",
    "    try:\n",
    "        code_dataset = json.load(f)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing line in {valid_code_path}: {e}\")\n",
    "\n",
    "# 读取test_query_process.json文件 \n",
    "test_query_path = \"/home/yiming/cophi/projects/fork/CoSQA_Plus/datasetBuild/dataset/test_query_process.json\"\n",
    "comment_dataset = []\n",
    "with open(test_query_path, \"r\") as f:\n",
    "    try:\n",
    "        comment_dataset = json.load(f)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing {test_query_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# 文件路径\n",
    "json_file_path = '/home/yiming/cophi/training_dynamic/features/only_aa_labeled_multi_epochs_cls_cosqa/cosqa_tokenized_code_tokens.json'\n",
    "\n",
    "\n",
    "# 读取JSON文件\n",
    "with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "    code_tokens_data = json.load(f)\n",
    "\n",
    "# 文件路径\n",
    "json_file_path = '/home/yiming/cophi/training_dynamic/features/only_aa_labeled_multi_epochs_cls_cosqa/cosqa_tokenized_nl_tokens.json'\n",
    "\n",
    "\n",
    "# 读取JSON文件\n",
    "with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "    nl_tokens_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ind = 0\n",
    "convert_idx = 15633\n",
    "convert_idx_code = 7013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query idx is at position 1108 in comment_dataset\n"
     ]
    }
   ],
   "source": [
    "query_idx = None\n",
    "for i, item in enumerate(comment_dataset):\n",
    "    if item['query-idx'] == convert_idx:\n",
    "        query_idx = i\n",
    "        break\n",
    "print(f\"Query idx is at position {query_idx} in comment_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "for i in range(1, 2):\n",
    "    source_file = f'/home/yiming/cophi/training_dynamic/features/only_aa_labeled_multi_epochs/Epoch_{i}/cosqa_nl_tokens_curr.npy'\n",
    "    destination_file = f'/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp/dataset/features/nl_tokens_{i}.npy'\n",
    "    shutil.copyfile(source_file, destination_file)\n",
    "for i in range(1, 2):\n",
    "    source_file = f'/home/yiming/cophi/training_dynamic/features/only_aa_labeled_multi_epochs/Epoch_{i}/cosqa_code_tokens_curr.npy'\n",
    "    destination_file = f'/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp/dataset/features/code_tokens_{i}.npy'\n",
    "    shutil.copyfile(source_file, destination_file)\n",
    "    \n",
    "for i in range(1, 2):\n",
    "    source_file = f'/home/yiming/cophi/training_dynamic/features/only_aa_labeled_multi_epochs/Epoch_{i}/cosqa_nl_attention_curr.npy'\n",
    "    destination_file = f'/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp/dataset/features/nl_attention_{i}.npy'\n",
    "    shutil.copyfile(source_file, destination_file)\n",
    "for i in range(1, 2):\n",
    "    source_file = f'/home/yiming/cophi/training_dynamic/features/only_aa_labeled_multi_epochs/Epoch_{i}/cosqa_code_attention_curr.npy'\n",
    "    destination_file = f'/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp/dataset/features/code_attention_{i}.npy'\n",
    "    shutil.copyfile(source_file, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 文件路径\n",
    "nl_tokens_paths = [f'/home/yiming/cophi/training_dynamic/features/only_aa_labeled_multi_epochs/Epoch_{i}/cosqa_nl_tokens_curr.npy' for i in range(1, 2)]\n",
    "code_tokens_paths = [f'/home/yiming/cophi/training_dynamic/features/only_aa_labeled_multi_epochs/Epoch_{i}/cosqa_code_tokens_curr.npy' for i in range(1, 2)]\n",
    "\n",
    "# 读取nl_tokens.npy\n",
    "all_nl_tokens_list = []\n",
    "for path in nl_tokens_paths:\n",
    "    all_nl_tokens_list.append(np.load(path))\n",
    "\n",
    "# 读取code_tokens.npy \n",
    "all_code_tokens_list = []\n",
    "for path in code_tokens_paths:\n",
    "    all_code_tokens_list.append(np.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文件路径\n",
    "code_attention_paths = [f'/home/yiming/cophi/training_dynamic/features/only_aa_labeled_multi_epochs/Epoch_{i}/cosqa_code_attention_curr.npy' for i in range(1, 2)]\n",
    "nl_attention_paths = [f'/home/yiming/cophi/training_dynamic/features/only_aa_labeled_multi_epochs/Epoch_{i}/cosqa_nl_attention_curr.npy' for i in range(1, 2)]\n",
    "\n",
    "# 读取code attention features\n",
    "code_attention_features = []\n",
    "for path in code_attention_paths:\n",
    "    code_attention_features.append(np.load(path))\n",
    "\n",
    "# 读取nl attention features\n",
    "nl_attention_features = []\n",
    "for path in nl_attention_paths:\n",
    "    nl_attention_features.append(np.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_data = code_tokens_data[convert_idx_code]\n",
    "comment_data = nl_tokens_data[query_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理完成！\n"
     ]
    }
   ],
   "source": [
    "output_dir = '/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp/dataset/sample'\n",
    "\n",
    "# 确保输出目录存在\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 遍历列表的每一项\n",
    "for i, token_list in enumerate(comment_data):\n",
    "   \n",
    "    # 生成输出文件路径\n",
    "    output_file_path = os.path.join(output_dir, f'text_{i}.txt')\n",
    "    \n",
    "    # 保存到文件中，去除G点符号并加上序号\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as f_out:\n",
    "        token_str = str(comment_data[i]).replace('Ġ', '')\n",
    "        f_out.write(f\"{i}: {token_str}\")\n",
    "    # 找到</s>的位置，并保留其之前的部分\n",
    "    if '</s>' == token_list:\n",
    "        comment_length = i\n",
    "        break\n",
    "\n",
    "print(\"处理完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理完成！\n"
     ]
    }
   ],
   "source": [
    "output_dir = '/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp/dataset/sample/'\n",
    "\n",
    "# 确保输出目录存在\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 遍历列表的每一项\n",
    "for i, token_list in enumerate(code_data):\n",
    "   \n",
    "    # 生成输出文件路径\n",
    "    output_file_path = os.path.join(output_dir, f'text_{i+comment_length+1}.txt')\n",
    "    \n",
    "    # 保存到文件中，去除G点符号并加上序号\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as f_out:\n",
    "        token_str = str(code_data[i]).replace('Ġ', '')\n",
    "        f_out.write(f\"{i}: {token_str}\")\n",
    "    # 找到</s>的位置，并保留其之前的部分\n",
    "    if '</s>' == token_list:\n",
    "        code_length = i\n",
    "        break\n",
    "\n",
    "print(\"处理完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create labels\n",
    "labels = [0]*comment_length + [1]*code_length\n",
    "\n",
    "# Save labels to file\n",
    "output_dir = '/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp/dataset/label/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, 'labels.npy')\n",
    "np.save(output_path, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp/dataset'\n",
    "code_text = '<s> ' + code_dataset[convert_idx_code]['code']\n",
    "comment_text = '<s> ' + comment_dataset[query_idx]['query']\n",
    "# Create dictionary with the required data\n",
    "data_dict = {\n",
    "    'code': code_text,  # Original code text from training dataset\n",
    "    'docstring': comment_text,  # Original docstring text from training dataset\n",
    "    'code_tokens': code_data[:code_length],  # Code tokens after truncation\n",
    "    'comment_tokens': comment_data[:comment_length]  # Comment tokens after truncation\n",
    "}\n",
    "\n",
    "# Save to full_text.json\n",
    "output_path = os.path.join(output_dir, 'full_text.json')\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(data_dict, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 data shape: (60, 768)\n"
     ]
    }
   ],
   "source": [
    "# 获取 n 和 m\n",
    "n = comment_length\n",
    "m = code_length\n",
    "\n",
    "# 对每个epoch分别处理\n",
    "for epoch in range(1, 2):\n",
    "    # 读取当前epoch的nl_tokens和code_tokens\n",
    "    nl_tokens = all_nl_tokens_list[epoch-1][data_ind][:n]\n",
    "    code_tokens = all_code_tokens_list[epoch-1][data_ind][:m]\n",
    "    \n",
    "    # nl_tokens[0] = nl_cls_tokens[comment_id]\n",
    "    # code_tokens[0] = code_cls_tokens[data_ind]\n",
    "    \n",
    "    # 拼接两部分数据\n",
    "    combined_data = np.concatenate((nl_tokens, code_tokens))\n",
    "    print(f\"Epoch {epoch} data shape:\", combined_data.shape)\n",
    "    \n",
    "    # 检查并创建保存目录\n",
    "    output_dir = f'/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp/Model/Epoch_{epoch}'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # 保存到对应epoch的目录\n",
    "    output_path = os.path.join(output_dir, 'train_data.npy')\n",
    "    np.save(output_path, combined_data)\n",
    "    # print(f\"Epoch {epoch} 数据已保存到 {output_path}\")\n",
    "    # Save to visualization directory\n",
    "    visualize_dir = f'/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp/visualize/DVI/high_dim'\n",
    "    if not os.path.exists(visualize_dir):\n",
    "        os.makedirs(visualize_dir)\n",
    "    visualize_output_path = os.path.join(visualize_dir, f'train_data_{epoch}.npy')\n",
    "    np.save(visualize_output_path, combined_data)\n",
    "    # print(f\"Epoch {epoch} 数据已保存到 {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 生成从0到m-1的索引\n",
    "indices = list(range(n,n+m))\n",
    "\n",
    "# 为每个epoch创建并保存索引\n",
    "for epoch in range(1, 2):\n",
    "    # 生成当前epoch的输出路径\n",
    "    output_dir = f'/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    index_output_path = os.path.join(output_dir, 'code_index.json')\n",
    "    \n",
    "    # 将索引保存到index.json中\n",
    "    with open(index_output_path, 'w', encoding='utf-8') as f_out:\n",
    "        json.dump(indices, f_out, ensure_ascii=False, indent=4)\n",
    "        \n",
    "    # print(f\"索引已保存到 {index_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成从0到n-1的索引\n",
    "indices = list(range(n))\n",
    "\n",
    "# 为每个epoch创建并保存索引\n",
    "for epoch in range(1, 2):\n",
    "    # 生成当前epoch的输出路径\n",
    "    output_dir = f'/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    data_index_output_path = os.path.join(output_dir, 'comment_index.json')\n",
    "    \n",
    "    # 将索引保存到data_index.json中\n",
    "    with open(data_index_output_path, 'w', encoding='utf-8') as f_out:\n",
    "        json.dump(indices, f_out, ensure_ascii=False, indent=4)\n",
    "        \n",
    "    # print(f\"索引已保存到 {data_index_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成从0到n+m-1的索引\n",
    "indices = list(range(len(combined_data)))\n",
    "\n",
    "# 为每个epoch创建并保存索引\n",
    "for epoch in range(1, 2):\n",
    "    # 生成当前epoch的输出路径\n",
    "    output_dir = f'/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp/Model/Epoch_{epoch}'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    index_output_path = os.path.join(output_dir, 'index.json')\n",
    "    \n",
    "    # 将索引保存到index.json中\n",
    "    with open(index_output_path, 'w', encoding='utf-8') as f_out:\n",
    "        json.dump(indices, f_out, ensure_ascii=False, indent=4)\n",
    "        \n",
    "    # print(f\"索引已保存到 {index_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 初始化存储所有epoch数据的列表\n",
    "all_intra_comment_sims = []\n",
    "all_intra_code_sims = []\n",
    "all_inter_comment_code_sims = []\n",
    "all_inter_code_comment_sims = []\n",
    "\n",
    "# 对每个epoch进行处理\n",
    "for epoch in range(1, 2):\n",
    "    # 读取数据\n",
    "    data_path = f'/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp/Model/Epoch_{epoch}/train_data.npy'\n",
    "    data = np.load(data_path)\n",
    "\n",
    "    # 读取 comment token 长度\n",
    "    data_index_path = f'/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp/comment_index.json'\n",
    "    with open(data_index_path, 'r') as f:\n",
    "        comment_length = len(json.load(f))\n",
    "\n",
    "    # 将数据分为前半部分的comment和后半部分的code\n",
    "    comments = data[:comment_length]  # 前半部分是comment\n",
    "    code_tokens = data[comment_length:]  # 后半部分是code\n",
    "\n",
    "    # 计算相似度函数（使用余弦相似度）\n",
    "    def compute_similarity(tokens_a, tokens_b):\n",
    "        return cosine_similarity(tokens_a, tokens_b)\n",
    "\n",
    "    # intra 相似度计算\n",
    "    intra_comment_sim = compute_similarity(comments, comments)\n",
    "    intra_code_sim = compute_similarity(code_tokens, code_tokens)\n",
    "\n",
    "    # inter 相似度计算\n",
    "    inter_comment_code_sim = compute_similarity(comments, code_tokens)\n",
    "    inter_code_comment_sim = compute_similarity(code_tokens, comments)\n",
    "\n",
    "    # 获取前 k 个最近邻\n",
    "    k = 10  # 假设我们需要前 5 个最近邻\n",
    "\n",
    "    # intra 计算\n",
    "    def get_intra_neighbors(sim_matrix, k, offset=0):\n",
    "        neighbors = []\n",
    "        for i in range(len(sim_matrix)):\n",
    "            # 获取当前样本对其他样本的相似度排序\n",
    "            sorted_indices = np.argsort(-sim_matrix[i])\n",
    "            # 如果样本数量不足k个，用自身的索引补齐\n",
    "            if len(sorted_indices) < k:\n",
    "                needed = k - len(sorted_indices)\n",
    "                neighbors.append(np.concatenate([\n",
    "                    sorted_indices + offset,\n",
    "                    np.array([i + offset] * needed)\n",
    "                ]))\n",
    "            else:\n",
    "                neighbors.append(sorted_indices[:k] + offset)\n",
    "        return np.array(neighbors)\n",
    "\n",
    "    intra_comment_neighbors = get_intra_neighbors(intra_comment_sim, k)\n",
    "    intra_code_neighbors = get_intra_neighbors(intra_code_sim, k, comment_length)\n",
    "\n",
    "    # inter 计算 - 应该使用专门的函数处理comment到code的映射\n",
    "    def get_comment_to_code_neighbors(sim_matrix, k, code_offset):\n",
    "        neighbors = []\n",
    "        for i in range(len(sim_matrix)):\n",
    "            # 获取当前注释对所有代码的相似度排序\n",
    "            sorted_indices = np.argsort(-sim_matrix[i])\n",
    "            # 将代码的索引加上offset以对应实际位置\n",
    "            neighbors.append(sorted_indices[:k] + code_offset)\n",
    "        return np.array(neighbors)\n",
    "\n",
    "    inter_comment_neighbors = get_comment_to_code_neighbors(inter_comment_code_sim, k, comment_length)  # comment 对 code 的相似度\n",
    "    \n",
    "    def get_code_to_comment_neighbors(sim_matrix, k, comment_length):\n",
    "        neighbors = []\n",
    "        for i in range(len(sim_matrix)):\n",
    "            # 获取当前代码对所有注释的相似度排序\n",
    "            sorted_indices = np.argsort(-sim_matrix[i])\n",
    "            # 如果注释数量不足k个，用代码自身的索引补齐\n",
    "            if len(sorted_indices) < k:\n",
    "                needed = k - len(sorted_indices)\n",
    "                neighbors.append(np.concatenate([\n",
    "                    sorted_indices,\n",
    "                    np.array([i + comment_length] * needed)\n",
    "                ]))\n",
    "            else:\n",
    "                neighbors.append(sorted_indices[:k])\n",
    "        return np.array(neighbors)\n",
    "\n",
    "    inter_code_neighbors = get_code_to_comment_neighbors(inter_code_comment_sim, k, comment_length)\n",
    "\n",
    "    # 拼接 intra 和 inter 结果\n",
    "    intra_neighbors = np.concatenate([intra_comment_neighbors, intra_code_neighbors], axis=0)\n",
    "    inter_neighbors = np.concatenate([inter_comment_neighbors, inter_code_neighbors], axis=0)\n",
    "\n",
    "    # 将当前epoch的结果添加到列表中\n",
    "    all_intra_comment_sims.append(intra_comment_sim)\n",
    "    all_intra_code_sims.append(intra_code_sim)\n",
    "    all_inter_comment_code_sims.append(inter_comment_code_sim)\n",
    "    all_inter_code_comment_sims.append(inter_code_comment_sim)\n",
    "\n",
    "    # 保存每个epoch的邻居信息\n",
    "    intra_save_dir = '/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp/dataset/intra_similarity'\n",
    "    inter_save_dir = '/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp/dataset/inter_similarity'\n",
    "    \n",
    "    import os\n",
    "    if not os.path.exists(intra_save_dir):\n",
    "        os.makedirs(intra_save_dir)\n",
    "    if not os.path.exists(inter_save_dir):\n",
    "        os.makedirs(inter_save_dir)\n",
    "\n",
    "\n",
    "    # 保存邻居信息\n",
    "    np.save(os.path.join(intra_save_dir, f'{epoch}.npy'), intra_neighbors)\n",
    "    np.save(os.path.join(inter_save_dir, f'{epoch}.npy'), inter_neighbors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inter_neighbors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3 style='margin:0'>Epoch 1</h3><h4 style='margin:0'>Comment:</h4><pre><span style=\"font-size: 11.932359218597412px;\">check</span> <span style=\"font-size: 16.0px;\">if</span> <span style=\"font-size: 8.0px;\">env</span> <span style=\"font-size: 13.489308834075928px;\">exists</span> <span style=\"font-size: 8.510637640953064px;\">python</span></pre><h4 style='margin:0'>Code:</h4><pre><span style=\"font-size: 14.040279865264893px;\">def</span> <span style=\"font-size: 14.665769577026367px;\">python</span><span style=\"font-size: 8.293641805648804px;\">(</span><span style=\"font-size: 11.64088225364685px;\">self</span><span style=\"font-size: 8.015733202919364px;\">)</span><span style=\"font-size: 8.0px;\">:</span><br>    <span style=\"font-size: 9.657185435295105px;\">try</span><span style=\"font-size: 8.233208119869232px;\">:</span><br>        <span style=\"font-size: 10.907164812088013px;\">ven</span><span style=\"font-size: 10.713006258010864px;\">v</span> <span style=\"font-size: 8.124853566288948px;\">=</span> <span style=\"font-size: 10.982032060623169px;\">os</span><span style=\"font-size: 10.284695148468018px;\">.</span><span style=\"font-size: 10.60684871673584px;\">en</span><span style=\"font-size: 10.432026863098145px;\">viron</span><span style=\"font-size: 8.724697649478912px;\">[</span><span style=\"font-size: 9.281589031219482px;\">'</span><span style=\"font-size: 9.714048504829407px;\">V</span><span style=\"font-size: 9.585969805717468px;\">IRT</span><span style=\"font-size: 9.533494114875793px;\">UAL</span><span style=\"font-size: 8.902674317359924px;\">_</span><span style=\"font-size: 9.657284379005432px;\">EN</span><span style=\"font-size: 9.612865090370178px;\">V</span><span style=\"font-size: 9.169816493988037px;\">'</span><span style=\"font-size: 8.1331477612257px;\">]</span><br>        <span style=\"font-size: 15.94938325881958px;\">return</span> <span style=\"font-size: 11.263250827789307px;\">os</span><span style=\"font-size: 10.230878114700317px;\">.</span><span style=\"font-size: 12.048048973083496px;\">path</span><span style=\"font-size: 10.364888191223145px;\">.</span><span style=\"font-size: 12.517795085906982px;\">join</span><span style=\"font-size: 8.154668599367142px;\">(</span><span style=\"font-size: 10.665295362472534px;\">ven</span><span style=\"font-size: 10.359354496002197px;\">v</span><span style=\"font-size: 8.024036450311542px;\">,</span> <span style=\"font-size: 9.422341704368591px;\">'</span><span style=\"font-size: 12.153480052947998px;\">bin</span><span style=\"font-size: 9.332342982292175px;\">'</span><span style=\"font-size: 8.080883912742138px;\">,</span> <span style=\"font-size: 9.333189606666565px;\">'</span><span style=\"font-size: 11.798349380493164px;\">python</span><span style=\"font-size: 10.795294761657715px;\">3</span><span style=\"font-size: 9.069841146469116px;\">'</span><span style=\"font-size: 8.002600130159408px;\">)</span><br>    <span style=\"font-size: 9.458921313285828px;\">except</span> <span style=\"font-size: 9.608765602111816px;\">Key</span><span style=\"font-size: 9.638143181800842px;\">Error</span><span style=\"font-size: 8.022089375182986px;\">:</span><br>        <span style=\"font-size: 16.0px;\">return</span> <span style=\"font-size: 9.759249806404114px;\">'</span><span style=\"font-size: 11.5986967086792px;\">python</span><span style=\"font-size: 10.860703706741333px;\">3</span><span style=\"font-size: 10.602365493774414px;\">'</span></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import deque\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import time\n",
    "\n",
    "# 处理code部分\n",
    "code_snippet = remove_docstrings(code_dataset[convert_idx_code][\"code\"])\n",
    "token_list2 = code_tokens_data[convert_idx_code][1:]\n",
    "token_list1 = nl_tokens_data[query_idx][1:]\n",
    "# Get docstring and remove parameter descriptions\n",
    "doc_snippet = comment_dataset[query_idx][\"query\"].split(\"\\n\")[0]\n",
    "# Remove any parts of code_snippet that appear in doc_snippet\n",
    "doc_words = set(doc_snippet.lower().split())\n",
    "code_lines = code_snippet.split('\\n')\n",
    "filtered_code_lines = []\n",
    "\n",
    "for line in code_lines:\n",
    "    # Skip line if it contains too many words from docstring\n",
    "    line_words = set(line.lower().split())\n",
    "    overlap = len(line_words.intersection(doc_words))\n",
    "    if overlap < len(line_words) / 2:  # Keep line if less than 50% overlap\n",
    "        filtered_code_lines.append(line)\n",
    "\n",
    "code_snippet = '\\n'.join(filtered_code_lines)\n",
    "\n",
    "# 对1-50 epoch分别计算\n",
    "for epoch in range(1, 2):\n",
    "    # 清除上一次的输出\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    # 处理comment部分\n",
    "    array = nl_attention_features[epoch-1][data_ind]  # 从list中获取对应epoch的数据\n",
    "    array = array[1:comment_length]\n",
    "    \n",
    "    normalized_contributions = (array - array.min()) / (array.max() - array.min())\n",
    "    tokens_with_contributions = deque([(token.replace(\"Ġ\", \"\"), contrib) for token, contrib in zip(token_list1, normalized_contributions)])\n",
    "\n",
    "    code_attention_feature = code_attention_features[epoch-1][data_ind][1:code_length]\n",
    "    code_normalized_contributions = (code_attention_feature - code_attention_feature.min()) / (code_attention_feature.max() - code_attention_feature.min())\n",
    "    code_tokens_with_contributions = deque([(token.replace(\"Ġ\", \"\"), contrib) for token, contrib in zip(token_list2, code_normalized_contributions)])\n",
    "\n",
    "    # 生成HTML输出\n",
    "    html_string = f\"<h3 style='margin:0'>Epoch {epoch}</h3>\"\n",
    "    \n",
    "    # Comment部分\n",
    "    html_string += \"<h4 style='margin:0'>Comment:</h4><pre>\"\n",
    "    buffer = \"\"\n",
    "    current_index = 0\n",
    "    for char in doc_snippet:\n",
    "        if char == \"\\n\":\n",
    "            html_string += buffer + \"<br>\"\n",
    "            buffer = \"\"\n",
    "        elif tokens_with_contributions:\n",
    "            token, contrib = tokens_with_contributions[0]\n",
    "            buffer += char\n",
    "            if buffer == token:\n",
    "                font_size = 8 + (16 - 8) * contrib\n",
    "                html_string += f'<span style=\"font-size: {font_size}px;\">{buffer}</span>'\n",
    "                buffer = \"\"\n",
    "                tokens_with_contributions.popleft()\n",
    "                current_index += 1\n",
    "            elif not token.startswith(buffer):\n",
    "                html_string += buffer[0]\n",
    "                buffer = buffer[1:]\n",
    "        else:\n",
    "            html_string += char\n",
    "    html_string += buffer + \"</pre>\"\n",
    "\n",
    "    # Code部分\n",
    "    html_string += \"<h4 style='margin:0'>Code:</h4><pre>\"\n",
    "    buffer = \"\"\n",
    "    current_index = 0\n",
    "    for char in code_snippet:\n",
    "        if char == \"\\n\":\n",
    "            html_string += buffer + \"<br>\"\n",
    "            buffer = \"\"\n",
    "        elif code_tokens_with_contributions:\n",
    "            token, contrib = code_tokens_with_contributions[0]\n",
    "            buffer += char\n",
    "            if buffer == token:\n",
    "                font_size = 8 + (16 - 8) * contrib\n",
    "                html_string += f'<span style=\"font-size: {font_size}px;\">{buffer}</span>'\n",
    "                buffer = \"\"\n",
    "                code_tokens_with_contributions.popleft()\n",
    "                current_index += 1\n",
    "            elif not token.startswith(buffer):\n",
    "                html_string += buffer[0]\n",
    "                buffer = buffer[1:]\n",
    "        else:\n",
    "            html_string += char\n",
    "    html_string += buffer + \"</pre>\"\n",
    "\n",
    "    # 显示结果\n",
    "    display(HTML(html_string))\n",
    "    \n",
    "    # 添加延迟以便观察动画效果\n",
    "    time.sleep(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预设20种颜色\n",
    "high_contrast_colors = [\n",
    "    \"#FF0000\", \"#00FF00\", \"#0000FF\", \"#FFA500\", \"#FF00FF\", \n",
    "    \"#00FFFF\", \"#800000\", \"#008000\", \"#000080\", \"#808000\",\n",
    "    \"#FF4500\", \"#FFD700\", \"#FF6347\", \"#FF69B4\", \"#FF1493\",\n",
    "    \"#FF00FF\", \"#FF8C00\", \"#FFA07A\", \"#FFB6C1\", \"#FFDAB9\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 768)\n",
      "发现 4 个聚类群组\n",
      "\n",
      "群组 1 (大小: 24):\n",
      "  代码 token 索引: [0, 1, 8, 9, 11, 12, 13, 14, 25, 26, 27, 28, 29, 30, 32, 33, 36, 40, 41, 48, 50, 51, 52]\n",
      "  注释 token 索引: [0]\n",
      "\n",
      "群组 2 (大小: 1):\n",
      "  代码 token 索引: [3]\n",
      "  注释 token 索引: []\n",
      "\n",
      "群组 3 (大小: 1):\n",
      "  代码 token 索引: []\n",
      "  注释 token 索引: [1]\n",
      "\n",
      "群组 4 (大小: 1):\n",
      "  代码 token 索引: []\n",
      "  注释 token 索引: [3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "selected_epoch = 1\n",
    "\n",
    "# 读取 comment token 长度\n",
    "data_index_path = f'/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp/comment_index.json'\n",
    "with open(data_index_path, 'r') as f:\n",
    "    comment_length = len(json.load(f))\n",
    "\n",
    "data_index_path = f'/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp/code_index.json'\n",
    "with open(data_index_path, 'r') as f:\n",
    "    code_length = len(json.load(f))\n",
    "\n",
    "# Load train data for the selected epoch\n",
    "output_dir = f'/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp/visualize/DVI/high_dim'\n",
    "train_data_path = os.path.join(output_dir, f'train_data_{selected_epoch}.npy')\n",
    "train_data = np.load(train_data_path)\n",
    "\n",
    "# Split train data based on comment length and code length\n",
    "comment_vectors = train_data[:comment_length]\n",
    "code_vectors = train_data[comment_length:]\n",
    "\n",
    "# 设置相似度阈值\n",
    "similarity_threshold = 0.65  # 用于判断相似性\n",
    "\n",
    "# 加载代码和注释的注意力数据\n",
    "code_attention = code_attention_features[selected_epoch-1][data_ind][1:code_length]\n",
    "comment_attention = nl_attention_features[selected_epoch-1][data_ind][1:comment_length]\n",
    "\n",
    "# 计算代码和注释的平均注意力\n",
    "avg_code_attention = np.mean(code_attention)\n",
    "avg_comment_attention = np.mean(comment_attention)\n",
    "\n",
    "# 筛选高于平均注意力的索引\n",
    "filtered_code_indices = np.where(code_attention > avg_code_attention)[0]\n",
    "filtered_comment_indices = np.where(comment_attention > avg_comment_attention)[0]\n",
    "\n",
    "# 提取对应的代码和注释向量\n",
    "filtered_code_vectors = code_vectors[1:][filtered_code_indices]\n",
    "filtered_comment_vectors = comment_vectors[1:][filtered_comment_indices]\n",
    "\n",
    "# 合并代码和注释向量作为聚类数据\n",
    "combined_vectors = np.vstack((filtered_code_vectors, filtered_comment_vectors))\n",
    "print(combined_vectors.shape)\n",
    "\n",
    "# 计算余弦相似度矩阵\n",
    "similarity_matrix = cosine_similarity(combined_vectors)\n",
    "\n",
    "# 将相似度转换为距离（确保相似度不超出范围）\n",
    "distance_matrix = 1 - similarity_matrix\n",
    "\n",
    "# 将所有负值截断为 0，避免数值误差导致问题\n",
    "distance_matrix = np.clip(distance_matrix, 0, None)\n",
    "\n",
    "clustering = DBSCAN(eps=1-similarity_threshold, min_samples=1, metric='precomputed').fit(distance_matrix)\n",
    "\n",
    "# 获取聚类标签\n",
    "cluster_labels = clustering.labels_\n",
    "\n",
    "# 记录索引的映射（用于恢复原始索引）\n",
    "original_indices = np.concatenate((filtered_code_indices, filtered_comment_indices + code_length))\n",
    "\n",
    "# 存储聚类结果\n",
    "clusters = {}\n",
    "for idx, label in enumerate(cluster_labels):\n",
    "    if label == -1:\n",
    "        continue  # 跳过噪声点\n",
    "    if label not in clusters:\n",
    "        clusters[label] = {'code_indices': set(), 'comment_indices': set()}\n",
    "    \n",
    "    original_idx = original_indices[idx]\n",
    "    if original_idx < code_length:\n",
    "        clusters[label]['code_indices'].add(original_idx)\n",
    "    else:\n",
    "        clusters[label]['comment_indices'].add(original_idx - code_length)\n",
    "\n",
    "# 按群组大小排序\n",
    "sorted_clusters = sorted(clusters.items(), key=lambda x: len(x[1]['code_indices']) + len(x[1]['comment_indices']), reverse=True)\n",
    "\n",
    "# 打印结果\n",
    "print(f\"发现 {len(sorted_clusters)} 个聚类群组\")\n",
    "for group_idx, (label, group) in enumerate(sorted_clusters):\n",
    "    print(f\"\\n群组 {group_idx + 1} (大小: {len(group['code_indices']) + len(group['comment_indices'])}):\")\n",
    "    print(f\"  代码 token 索引: {sorted(list(group['code_indices']))}\")\n",
    "    print(f\"  注释 token 索引: {sorted(list(group['comment_indices']))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  {'code_indices': {0,\n",
       "    1,\n",
       "    8,\n",
       "    9,\n",
       "    11,\n",
       "    12,\n",
       "    13,\n",
       "    14,\n",
       "    25,\n",
       "    26,\n",
       "    27,\n",
       "    28,\n",
       "    29,\n",
       "    30,\n",
       "    32,\n",
       "    33,\n",
       "    36,\n",
       "    40,\n",
       "    41,\n",
       "    48,\n",
       "    50,\n",
       "    51,\n",
       "    52},\n",
       "   'comment_indices': {0}}),\n",
       " (1, {'code_indices': {3}, 'comment_indices': set()}),\n",
       " (2, {'code_indices': set(), 'comment_indices': {1}}),\n",
       " (3, {'code_indices': set(), 'comment_indices': {3}})]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_clusters[0][1]['comment_indices'] = {0,3}\n",
    "sorted_clusters[2][1]['comment_indices'] = {}\n",
    "# sorted_clusters[1][1]['comment_indices'] = {3}\n",
    "# sorted_clusters[13][1]['comment_indices'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4 style='margin:0'>Comment:</h4><pre><span style=\"font-size: 12.113197803497314px; color: #FF0000;\">check</span><span style=\"color: #0000FF;\"> </span><span style=\"font-size: 14.395226001739502px; color: #0000FF;\">if</span><span style=\"color: black;\"> </span><span style=\"font-size: 9.907065033912659px; color: black;\">env</span><span style=\"color: #FFA500;\"> </span><span style=\"font-size: 12.986677646636963px; color: #FFA500;\">exists</span><span style=\"color: black;\"> </span><span style=\"font-size: 10.193542957305908px; color: black;\">python</span></pre><h4 style='margin:0'>Code:</h4><pre><span style=\"font-size: 14.058547496795654px; color: #FF0000;\">def</span><span style=\"color: #FF0000;\"> </span><span style=\"font-size: 14.67820692062378px; color: #FF0000;\">python</span><span style=\"font-size: 8.365476310253143px; color: black;\">(</span><span style=\"font-size: 11.681515455245972px; color: #00FF00;\">self</span><span style=\"font-size: 8.090158201754093px; color: black;\">)</span><span style=\"font-size: 8.074571654200554px; color: black;\">:</span><br><span style=\"color: black;\"> </span><span style=\"color: black;\"> </span><span style=\"color: black;\"> </span><span style=\"color: black;\"> </span><span style=\"font-size: 9.716309666633606px; color: black;\">try</span><span style=\"font-size: 8.305605947971344px; color: black;\">:</span><br><span style=\"color: #FF0000;\"> </span><span style=\"color: #FF0000;\"> </span><span style=\"color: #FF0000;\"> </span><span style=\"color: #FF0000;\"> </span><span style=\"color: #FF0000;\"> </span><span style=\"color: #FF0000;\"> </span><span style=\"color: #FF0000;\"> </span><span style=\"color: #FF0000;\"> </span><span style=\"font-size: 10.95463752746582px; color: #FF0000;\">ven</span><span style=\"font-size: 10.762288808822632px; color: #FF0000;\">v</span><span style=\"color: black;\"> </span><span style=\"font-size: 8.198261395096779px; color: black;\">=</span><span style=\"color: #FF0000;\"> </span><span style=\"font-size: 11.028806686401367px; color: #FF0000;\">os</span><span style=\"font-size: 10.33797001838684px; color: #FF0000;\">.</span><span style=\"font-size: 10.657120704650879px; color: #FF0000;\">en</span><span style=\"font-size: 10.483928442001343px; color: #FF0000;\">viron</span><span style=\"font-size: 8.792514026165009px; color: black;\">[</span><span style=\"font-size: 9.34421443939209px; color: black;\">'</span><span style=\"font-size: 9.772642612457275px; color: black;\">V</span><span style=\"font-size: 9.645757794380188px; color: black;\">IRT</span><span style=\"font-size: 9.59377133846283px; color: black;\">UAL</span><span style=\"font-size: 8.968831658363342px; color: black;\">_</span><span style=\"font-size: 9.716407656669617px; color: black;\">EN</span><span style=\"font-size: 9.672402381896973px; color: black;\">V</span><span style=\"font-size: 9.233483672142029px; color: black;\">'</span><span style=\"font-size: 8.206478282809258px; color: black;\">]</span><br><span style=\"color: #FF0000;\"> </span><span style=\"color: #FF0000;\"> </span><span style=\"color: #FF0000;\"> </span><span style=\"color: #FF0000;\"> </span><span style=\"color: #FF0000;\"> </span><span style=\"color: #FF0000;\"> </span><span style=\"color: #FF0000;\"> </span><span style=\"color: #FF0000;\"> </span><span style=\"font-size: 15.949854850769043px; color: #FF0000;\">return</span><span style=\"color: #FF0000;\"> </span><span style=\"font-size: 11.307404041290283px; color: #FF0000;\">os</span><span style=\"font-size: 10.28465461730957px; color: #FF0000;\">.</span><span style=\"font-size: 12.084887027740479px; color: #FF0000;\">path</span><span style=\"font-size: 10.417415618896484px; color: #FF0000;\">.</span><span style=\"font-size: 12.550254344940186px; color: #FF0000;\">join</span><span style=\"font-size: 8.227798521518707px; color: black;\">(</span><span style=\"font-size: 10.715022325515747px; color: #FF0000;\">ven</span><span style=\"font-size: 10.411933422088623px; color: #FF0000;\">v</span><span style=\"font-size: 8.09838405251503px; color: black;\">,</span><span style=\"color: black;\"> </span><span style=\"font-size: 9.483654975891113px; color: black;\">'</span><span style=\"font-size: 12.189335346221924px; color: #FF0000;\">bin</span><span style=\"font-size: 9.394495129585266px; color: black;\">'</span><span style=\"font-size: 8.154701605439186px; color: black;\">,</span><span style=\"color: black;\"> </span><span style=\"font-size: 9.395334005355835px; color: black;\">'</span><span style=\"font-size: 11.837514877319336px; color: #FF0000;\">python</span><span style=\"font-size: 10.843810081481934px; color: #FF0000;\">3</span><span style=\"font-size: 9.134440302848816px; color: black;\">'</span><span style=\"font-size: 8.077147550880909px; color: black;\">)</span><br><span style=\"color: black;\"> </span><span style=\"color: black;\"> </span><span style=\"color: black;\"> </span><span style=\"color: black;\"> </span><span style=\"font-size: 9.519893646240234px; color: black;\">except</span><span style=\"color: black;\"> </span><span style=\"font-size: 9.668341159820557px; color: black;\">Key</span><span style=\"font-size: 9.697444796562195px; color: black;\">Error</span><span style=\"font-size: 8.096455127000809px; color: black;\">:</span><br><span style=\"color: #FF0000;\"> </span><span style=\"color: #FF0000;\"> </span><span style=\"color: #FF0000;\"> </span><span style=\"color: #FF0000;\"> </span><span style=\"color: #FF0000;\"> </span><span style=\"color: #FF0000;\"> </span><span style=\"color: #FF0000;\"> </span><span style=\"color: #FF0000;\"> </span><span style=\"font-size: 16.0px; color: #FF0000;\">return</span><span style=\"color: black;\"> </span><span style=\"font-size: 9.81742262840271px; color: black;\">'</span><span style=\"font-size: 11.639723062515259px; color: #FF0000;\">python</span><span style=\"font-size: 10.908609390258789px; color: #FF0000;\">3</span><span style=\"font-size: 10.652679204940796px; color: #FF0000;\">'</span></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "from collections import deque\n",
    "\n",
    "# Process code part\n",
    "code_snippet = remove_docstrings(code_dataset[convert_idx_code][\"code\"])\n",
    "token_list2 = code_tokens_data[convert_idx_code][1:]\n",
    "token_list1 = nl_tokens_data[query_idx][1:]\n",
    "\n",
    "# Get docstring and remove parameter descriptions\n",
    "doc_snippet = comment_dataset[query_idx][\"query\"].split(\"\\n\")[0]\n",
    "\n",
    "# Remove any parts of code_snippet that appear in doc_snippet\n",
    "doc_words = set(doc_snippet.lower().split())\n",
    "code_lines = code_snippet.split('\\n')\n",
    "filtered_code_lines = []\n",
    "\n",
    "for line in code_lines:\n",
    "    # Skip line if it contains too many words from docstring\n",
    "    line_words = set(line.lower().split())\n",
    "    overlap = len(line_words.intersection(doc_words))\n",
    "    if overlap < len(line_words) / 2:  # Keep line if less than 50% overlap\n",
    "        filtered_code_lines.append(line)\n",
    "\n",
    "code_snippet = '\\n'.join(filtered_code_lines)\n",
    "\n",
    "# Process comment part - using the similarity groups we defined earlier\n",
    "array = nl_attention_features[epoch-1][data_ind]  # Get data for current epoch\n",
    "array = array[1:]\n",
    "\n",
    "normalized_contributions = (array - array.min()) / (array.max() - array.min())\n",
    "tokens_with_contributions = deque([(token.replace(\"Ġ\", \"\"), contrib) for token, contrib in zip(token_list1, normalized_contributions)])\n",
    "\n",
    "code_attention_feature = code_attention_features[epoch-1][data_ind][1:]\n",
    "code_normalized_contributions = (code_attention_feature - code_attention_feature.min()) / (code_attention_feature.max() - code_attention_feature.min())\n",
    "code_tokens_with_contributions = deque([(token.replace(\"Ġ\", \"\"), contrib) for token, contrib in zip(token_list2, code_normalized_contributions)])\n",
    "\n",
    "# Use the similarity groups to assign colors\n",
    "# Each group contains {'codes': set(), 'comments': set()}\n",
    "color_map_comment = {}\n",
    "color_map_code = {}\n",
    "\n",
    "for group_idx, (label, group) in enumerate(sorted_clusters):\n",
    "    color = high_contrast_colors[group_idx % len(high_contrast_colors)]\n",
    "    for code_idx in group['code_indices']:\n",
    "        color_map_code[code_idx] = color\n",
    "    for comment_idx in group['comment_indices']:\n",
    "        color_map_comment[comment_idx] = color\n",
    "\n",
    "# Generate HTML output\n",
    "html_string = \"<h4 style='margin:0'>Comment:</h4><pre>\"\n",
    "buffer = \"\"\n",
    "current_index = 0\n",
    "for char in doc_snippet:\n",
    "    if char == \"\\n\":\n",
    "        html_string += buffer + \"<br>\"\n",
    "        buffer = \"\"\n",
    "    elif tokens_with_contributions:\n",
    "        token, contrib = tokens_with_contributions[0]\n",
    "        buffer += char\n",
    "        if buffer == token:\n",
    "            font_size = 8 + (16 - 8) * contrib\n",
    "            color = color_map_comment.get(current_index, \"black\")\n",
    "            html_string += f'<span style=\"font-size: {font_size}px; color: {color};\">{buffer}</span>'\n",
    "            buffer = \"\"\n",
    "            tokens_with_contributions.popleft()\n",
    "            current_index += 1\n",
    "        elif not token.startswith(buffer):\n",
    "            color = color_map_comment.get(current_index, \"black\")\n",
    "            html_string += f'<span style=\"color: {color};\">{buffer[0]}</span>'\n",
    "            buffer = buffer[1:]\n",
    "    else:\n",
    "        color = color_map_comment.get(current_index, \"black\")\n",
    "        html_string += f'<span style=\"color: {color};\">{char}</span>'\n",
    "html_string += buffer + \"</pre>\"\n",
    "\n",
    "# Code part\n",
    "html_string += \"<h4 style='margin:0'>Code:</h4><pre>\"\n",
    "buffer = \"\"\n",
    "current_index = 0\n",
    "for char in code_snippet:\n",
    "    if char == \"\\n\":\n",
    "        html_string += buffer + \"<br>\"\n",
    "        buffer = \"\"\n",
    "    elif code_tokens_with_contributions:\n",
    "        token, contrib = code_tokens_with_contributions[0]\n",
    "        buffer += char\n",
    "        if buffer == token:\n",
    "            font_size = 8 + (16 - 8) * contrib\n",
    "            color = color_map_code.get(current_index, \"black\")\n",
    "            html_string += f'<span style=\"font-size: {font_size}px; color: {color};\">{buffer}</span>'\n",
    "            buffer = \"\"\n",
    "            code_tokens_with_contributions.popleft()\n",
    "            current_index += 1\n",
    "        elif not token.startswith(buffer):\n",
    "            color = color_map_code.get(current_index, \"black\")\n",
    "            html_string += f'<span style=\"color: {color};\">{buffer[0]}</span>'\n",
    "            buffer = buffer[1:]\n",
    "    else:\n",
    "        color = color_map_code.get(current_index, \"black\")\n",
    "        html_string += f'<span style=\"color: {color};\">{char}</span>'\n",
    "html_string += buffer + \"</pre>\"\n",
    "\n",
    "# Display result\n",
    "display(HTML(html_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention sums by color group:\n",
      "\n",
      "Comment:\n",
      "\u001b[48;2;255;0;0m  \u001b[0m #FF0000: 0.2494\n",
      "\u001b[48;2;0;0;255m  \u001b[0m #0000FF: 0.3878\n",
      "\u001b[48;2;255;165;0m  \u001b[0m #FFA500: 0.3024\n",
      "\n",
      "Code:\n",
      "\u001b[48;2;255;0;0m  \u001b[0m #FF0000: 0.7209\n",
      "\u001b[48;2;0;255;0m  \u001b[0m #00FF00: 0.0306\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Calculate sum of attention by color groups\n",
    "color_groups_comment = {}\n",
    "color_groups_code = {}\n",
    "\n",
    "# Group attentions by color for comments\n",
    "for idx, color in color_map_comment.items():\n",
    "    if color not in color_groups_comment:\n",
    "        color_groups_comment[color] = []\n",
    "    color_groups_comment[color].append(array[idx]*2.5)\n",
    "\n",
    "# Group attentions by color for code\n",
    "for idx, color in color_map_code.items():\n",
    "    if color not in color_groups_code:\n",
    "        color_groups_code[color] = []\n",
    "    color_groups_code[color].append(code_attention_feature[idx])\n",
    "\n",
    "# Calculate sums for each color group\n",
    "comment_color_sums = {color: np.sum(attns) for color, attns in color_groups_comment.items()}\n",
    "code_color_sums = {color: np.sum(attns) for color, attns in color_groups_code.items()}\n",
    "\n",
    "# Print comparison with color blocks\n",
    "print(\"Attention sums by color group:\")\n",
    "print(\"\\nComment:\")\n",
    "for color, sum_val in comment_color_sums.items():\n",
    "    print(f\"\\033[48;2;{int(color[1:3],16)};{int(color[3:5],16)};{int(color[5:7],16)}m  \\033[0m {color}: {sum_val:.4f}\")\n",
    "    \n",
    "print(\"\\nCode:\")\n",
    "for color, sum_val in code_color_sums.items():\n",
    "    print(f\"\\033[48;2;{int(color[1:3],16)};{int(color[3:5],16)};{int(color[5:7],16)}m  \\033[0m {color}: {sum_val:.4f}\")\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "colors = list(set(color_map_comment.values()) | set(color_map_code.values()))\n",
    "x = np.arange(len(colors))\n",
    "width = 0.35\n",
    "\n",
    "comment_sums = [comment_color_sums.get(c, 0) for c in colors]\n",
    "code_sums = [code_color_sums.get(c, 0) for c in colors]\n",
    "\n",
    "# Use the same colors for both comment and code bars\n",
    "for i, (c_sum, cd_sum, color) in enumerate(zip(comment_sums, code_sums, colors)):\n",
    "    plt.bar(i - width/2, c_sum, width, color=color, alpha=0.7, label=f'Comment {color}' if i==0 else \"\")\n",
    "    plt.bar(i + width/2, cd_sum, width, color=color, alpha=0.3, label=f'Code {color}' if i==0 else \"\")\n",
    "\n",
    "plt.xlabel('Color Groups')\n",
    "plt.ylabel('Sum of Attention')\n",
    "plt.title('Comparison of Attention Sums by Color Group')\n",
    "\n",
    "# Create colored rectangles for x-axis labels\n",
    "ax = plt.gca()\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([''] * len(colors))  # Clear text labels\n",
    "for i, color in enumerate(colors):\n",
    "    ax.add_patch(plt.Rectangle((i-0.2, -0.1), 0.4, 0.05, color=color, transform=ax.transData))\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish initialization...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb 13 13:49:01 2025 Building RP forest with 5 trees\n",
      "Thu Feb 13 13:49:01 2025 NN descent for 6 iterations\n",
      "\t 1  /  6\n",
      "\t 2  /  6\n",
      "\t 3  /  6\n",
      "\tStopping threshold met -- exiting after 3 iterations\n",
      "complex-construct: 0.4825742244720459\n",
      "====================\n",
      "epoch:1\n",
      "===================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "umap:7.2372\trecon_l:0.2471\tnew_loss:7.2372\tloss:7.4844\n",
      "====================\n",
      "epoch:2\n",
      "===================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "umap:1.3844\trecon_l:0.1888\tnew_loss:1.3844\tloss:1.5732\n",
      "====================\n",
      "epoch:3\n",
      "===================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "umap:0.5657\trecon_l:1.3121\tnew_loss:0.5657\tloss:1.8778\n",
      "====================\n",
      "epoch:4\n",
      "===================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "umap:0.6611\trecon_l:0.2014\tnew_loss:0.6611\tloss:0.8626\n",
      "====================\n",
      "epoch:5\n",
      "===================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "umap:0.7616\trecon_l:11.7402\tnew_loss:0.7616\tloss:12.5019\n",
      "====================\n",
      "epoch:6\n",
      "===================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "umap:0.7046\trecon_l:4.7146\tnew_loss:0.7046\tloss:5.4192\n",
      "====================\n",
      "epoch:7\n",
      "===================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "umap:0.6809\trecon_l:1.4721\tnew_loss:0.6809\tloss:2.1530\n",
      "====================\n",
      "epoch:8\n",
      "===================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "umap:0.6975\trecon_l:0.4621\tnew_loss:0.6975\tloss:1.1595\n",
      "====================\n",
      "epoch:9\n",
      "===================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "umap:0.6706\trecon_l:0.2217\tnew_loss:0.6706\tloss:0.8923\n",
      "====================\n",
      "epoch:10\n",
      "===================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "umap:0.6808\trecon_l:0.2121\tnew_loss:0.6808\tloss:0.8929\n",
      "Time spend: 13.07 for training vis model...\n",
      "training: 13.069025993347168\n",
      "Successfully save visualization model...\n",
      "Finish epoch 1...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\"\n",
    "import time\n",
    "\n",
    "# # 读取高维向量 (num, 768)\n",
    "# input_path = '/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp/Model/Epoch_1/train_data.npy'\n",
    "# data = np.load(input_path)\n",
    "\n",
    "ENCODER_DIMS = [768,256,256,256,256,2]\n",
    "DECODER_DIMS = [2,256,256,256,256,768]\n",
    "\n",
    "CONTENT_PATH = '/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp'\n",
    "EPOCH_START = 1\n",
    "EPOCH_END = 1\n",
    "EPOCH_PERIOD = 1\n",
    "B_N_EPOCHS = 0\n",
    "N_NEIGHBORS = 8\n",
    "VIS_MODEL_NAME = 'dvi_aa'\n",
    "LAMBDA1 = 1\n",
    "S_N_EPOCHS = 5\n",
    "PATIENT = 3\n",
    "MAX_EPOCH = 10\n",
    "GPU_ID = 3\n",
    "DEVICE = torch.device(\"cuda:{}\".format(GPU_ID) if torch.cuda.is_available() else \"cpu\")\n",
    "net = \"Model\"\n",
    "CLASSES = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\"]\n",
    "\n",
    "# Define data_provider\n",
    "data_provider = NormalDataProvider(CONTENT_PATH, net, EPOCH_START, EPOCH_END, EPOCH_PERIOD, device=DEVICE, epoch_name='Epoch',classes=CLASSES,verbose=1)\n",
    "\n",
    "# Define visualization models\n",
    "model = VisModel(ENCODER_DIMS, DECODER_DIMS)\n",
    "\n",
    "# Define Losses\n",
    "negative_sample_rate = 5\n",
    "min_dist = .1\n",
    "_a, _b = find_ab_params(1.0, min_dist)\n",
    "\n",
    "umap_loss_fn = UmapLoss(negative_sample_rate, DEVICE, _a, _b, repulsion_strength=1.0)\n",
    "recon_loss_fn = ReconstructionLoss(beta=1.0)\n",
    "single_loss_fn = SingleVisLoss(umap_loss_fn, recon_loss_fn, lambd=1)\n",
    "# Define Projector\n",
    "projector = VISProjector(vis_model=model, content_path=CONTENT_PATH, vis_model_name=VIS_MODEL_NAME, device=DEVICE)\n",
    "\n",
    "prev_model = VisModel(ENCODER_DIMS, DECODER_DIMS)\n",
    "start_flag = 1\n",
    "\n",
    "for iteration in range(EPOCH_START, EPOCH_END+EPOCH_PERIOD, EPOCH_PERIOD):\n",
    "    # Define DVI Loss\n",
    "    if start_flag:\n",
    "        temporal_loss_fn = DummyTemporalLoss(DEVICE)\n",
    "        criterion = DVILoss(umap_loss_fn, recon_loss_fn, temporal_loss_fn, lambd1=1, lambd2=0.0,device=DEVICE)\n",
    "        start_flag = 0\n",
    "    else:\n",
    "        # TODO AL mode, redefine train_representation\n",
    "        prev_data = data_provider.train_representation(iteration-EPOCH_PERIOD)\n",
    "        prev_data = prev_data.reshape(prev_data.shape[0],prev_data.shape[1])\n",
    "        curr_data = data_provider.train_representation(iteration)\n",
    "        curr_data = curr_data.reshape(curr_data.shape[0],curr_data.shape[1])\n",
    "        print(prev_data.shape, curr_data.shape)\n",
    "        t_1= time.time()\n",
    "        npr = torch.tensor(find_neighbor_preserving_rate(prev_data, curr_data, N_NEIGHBORS)).to(DEVICE)\n",
    "        t_2= time.time()\n",
    "     \n",
    "        temporal_loss_fn = TemporalLoss(w_prev, DEVICE)\n",
    "        criterion = DVILoss(umap_loss_fn, recon_loss_fn, temporal_loss_fn, lambd1=1, lambd2=0.1*npr,device=DEVICE)\n",
    "\n",
    "    # Define training parameters\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=.01, weight_decay=1e-5)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=.1)\n",
    "    # Define Edge dataset\n",
    "\n",
    "    t0 = time.time()\n",
    "    ##### construct the spitial complex\n",
    "    spatial_cons = SingleEpochTextSpatialEdgeConstructor(data_provider, iteration, S_N_EPOCHS, B_N_EPOCHS, N_NEIGHBORS, net)\n",
    "    edge_to, edge_from, probs, feature_vectors, attention = spatial_cons.construct()\n",
    "    t1 = time.time()\n",
    "\n",
    "    print('complex-construct:', t1-t0)\n",
    "\n",
    "    probs = probs / (probs.max()+1e-3)\n",
    "    eliminate_zeros = probs> 1e-3    #1e-3\n",
    "    edge_to = edge_to[eliminate_zeros]\n",
    "    edge_from = edge_from[eliminate_zeros]#     probs = probs[eliminate_zeros]\n",
    "    \n",
    "    labels_non_boundary = np.zeros(len(edge_to))\n",
    "\n",
    "    # pred_list = data_provider.get_pred(iteration, feature_vectors)\n",
    "    pred_list = np.zeros(feature_vectors.shape)\n",
    "    dataset = VisDataHandler(edge_to, edge_from, feature_vectors, attention, probs,pred_list)\n",
    "\n",
    "    n_samples = int(np.sum(S_N_EPOCHS * probs) // 1)\n",
    "    # chose sampler based on the number of dataset\n",
    "    if len(edge_to) > pow(2,24):\n",
    "        sampler = CustomWeightedRandomSampler(probs, n_samples, replacement=True)\n",
    "    else:\n",
    "        sampler = WeightedRandomSampler(probs, n_samples, replacement=True)\n",
    "    edge_loader = DataLoader(dataset, batch_size=2000, sampler=sampler, num_workers=8, prefetch_factor=10)\n",
    "\n",
    "    ########################################################################################################################\n",
    "    #                                                       TRAIN                                                          #\n",
    "    ########################################################################################################################\n",
    "\n",
    "    trainer = BaseTextTrainer(model, criterion, optimizer, lr_scheduler, edge_loader=edge_loader, DEVICE=DEVICE)\n",
    "\n",
    "    t2=time.time()\n",
    "    trainer.train(PATIENT, MAX_EPOCH, data_provider,iteration)\n",
    "    t3 = time.time()\n",
    "    print('training:', t3-t2)\n",
    "    # save result\n",
    "    save_dir = data_provider.model_path\n",
    "    trainer.record_time(save_dir, \"time_{}\".format(VIS_MODEL_NAME), \"complex_construction\", str(iteration), t1-t0)\n",
    "    trainer.record_time(save_dir, \"time_{}\".format(VIS_MODEL_NAME), \"training\", str(iteration), t3-t2)\n",
    "    save_dir = os.path.join(data_provider.model_path, \"Epoch_{}\".format(iteration))\n",
    "    trainer.save(save_dir=save_dir, file_name=\"{}\".format(VIS_MODEL_NAME))\n",
    "\n",
    "    print(\"Finish epoch {}...\".format(iteration))\n",
    " \n",
    "    prev_model.load_state_dict(model.state_dict())\n",
    "    for param in prev_model.parameters():\n",
    "        param.requires_grad = False\n",
    "    w_prev = dict(prev_model.named_parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load the DVI visualization model for iteration 1\n",
      "x_min: -8.985813772678375, x_max: 34.43498001098633, y_min: -15.618302631378175, y_max: 26.97861557006836\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale saved to /home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp/Model/Epoch_1/scale.npy\n",
      "Embedding saved to /home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp/Model/Epoch_1/embedding.npy\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for iteration in range(EPOCH_START, EPOCH_END+EPOCH_PERIOD, EPOCH_PERIOD):\n",
    "    iter_data = data_provider.train_representation(iteration)\n",
    "    embedding = projector.batch_project(iteration, iter_data)\n",
    "    all_nodes_2d = embedding  # 使用你降维后的二维数据\n",
    "\n",
    "    x_min, y_min = np.min(all_nodes_2d, axis=0)\n",
    "    x_max, y_max = np.max(all_nodes_2d, axis=0)\n",
    "    # ebd_extent = ebd_max - ebd_min\n",
    "    x_extent = x_max - x_min\n",
    "    y_extent = y_max - y_min\n",
    "\n",
    "    x_min = x_min - 0.3 * x_extent\n",
    "    x_max = x_max + 0.3 * x_extent\n",
    "    y_min = y_min - 0.3 * y_extent\n",
    "    y_max = y_max + 0.3 * y_extent\n",
    "\n",
    "    # 打印结果\n",
    "    print(f\"x_min: {x_min}, x_max: {x_max}, y_min: {y_min}, y_max: {y_max}\")\n",
    "\n",
    "    # 将结果保存到指定文件夹\n",
    "    save_dir = os.path.join(data_provider.model_path, \"Epoch_{}\".format(iteration))\n",
    "    scale_path = os.path.join(save_dir, \"scale.npy\")\n",
    "    np.save(scale_path, [x_min, y_min, x_max, y_max])\n",
    "\n",
    "    # 保存embedding结果\n",
    "    embedding_path = os.path.join(save_dir, \"embedding.npy\") \n",
    "    np.save(embedding_path, embedding)\n",
    "\n",
    "    # 可视化 embedding 的二维散点图\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(embedding[:, 0], embedding[:, 1], s=5, cmap='Spectral', alpha=0.7)\n",
    "    plt.title('2D UMAP projection of the embeddings')\n",
    "    plt.xlabel('UMAP 1')\n",
    "    plt.ylabel('UMAP 2')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Scale saved to {scale_path}\")\n",
    "    print(f\"Embedding saved to {embedding_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 2):\n",
    "    source_file = f'/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp/Model/Epoch_{i}/embedding.npy'\n",
    "    destination_file = f'/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp/visualize/DVI/projection/{i}.npy'\n",
    "    shutil.copyfile(source_file, destination_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visualizer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
