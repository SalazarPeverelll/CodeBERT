{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from umap.umap_ import find_ab_params\n",
    "\n",
    "from singleVis.custom_weighted_random_sampler import CustomWeightedRandomSampler\n",
    "from singleVis.SingleVisualizationModel import VisModel\n",
    "from singleVis.losses import ReconstructionLoss, TemporalLoss, SingleVisLoss, DummyTemporalLoss\n",
    "from singleVis.backend import convert_distance_to_probability, compute_cross_entropy\n",
    "from singleVis.edge_dataset import VisDataHandler\n",
    "from singleVis.trainer import BaseTextTrainer\n",
    "from singleVis.eval.evaluator import Evaluator\n",
    "from singleVis.data import NormalDataProvider\n",
    "from singleVis.spatial_edge_constructor import SingleEpochTextSpatialEdgeConstructor\n",
    "\n",
    "from singleVis.projector import VISProjector\n",
    "from singleVis.utils import find_neighbor_preserving_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "class UmapLoss(nn.Module):\n",
    "    def __init__(self, negative_sample_rate, device, _a=1.0, _b=1.0, repulsion_strength=1.0):\n",
    "        super(UmapLoss, self).__init__()\n",
    "\n",
    "        self._negative_sample_rate = negative_sample_rate\n",
    "        self._a = _a,\n",
    "        self._b = _b,\n",
    "        self._repulsion_strength = repulsion_strength\n",
    "        self.DEVICE = torch.device(device)\n",
    "\n",
    "    @property\n",
    "    def a(self):\n",
    "        return self._a[0]\n",
    "\n",
    "    @property\n",
    "    def b(self):\n",
    "        return self._b[0]\n",
    "\n",
    "    def forward(self, embedding_to, embedding_from, probs):\n",
    "        # get negative samples\n",
    "        batch_size = embedding_to.shape[0]\n",
    "        embedding_neg_to = torch.repeat_interleave(embedding_to, self._negative_sample_rate, dim=0)\n",
    "        repeat_neg = torch.repeat_interleave(embedding_from, self._negative_sample_rate, dim=0)\n",
    "        randperm = torch.randperm(repeat_neg.shape[0])\n",
    "        embedding_neg_from = repeat_neg[randperm]\n",
    "        neg_num = len(embedding_neg_from)\n",
    "\n",
    "        positive_distance = torch.norm(embedding_to - embedding_from, dim=1)\n",
    "        negative_distance = torch.norm(embedding_neg_to - embedding_neg_from, dim=1)\n",
    "\n",
    "        distance_embedding = torch.cat(\n",
    "            (\n",
    "                positive_distance,\n",
    "                negative_distance,\n",
    "            ),\n",
    "            dim=0,\n",
    "        )\n",
    "        probabilities_distance = convert_distance_to_probability(\n",
    "            distance_embedding, self.a, self.b\n",
    "        )\n",
    "        probabilities_distance = probabilities_distance.to(self.DEVICE)\n",
    "\n",
    "        probabilities_graph = torch.cat(\n",
    "            (torch.ones(batch_size).to(self.DEVICE), torch.zeros(neg_num).to(self.DEVICE)), dim=0,\n",
    "        )\n",
    "\n",
    "        # probabilities_graph = torch.cat(\n",
    "        #     (probs.to(self.DEVICE), torch.zeros(neg_num).to(self.DEVICE)), dim=0,\n",
    "        # )\n",
    "\n",
    "        probabilities_graph = probabilities_graph.to(device=self.DEVICE)\n",
    "\n",
    "        # compute cross entropy\n",
    "        (_, _, ce_loss) = compute_cross_entropy(\n",
    "            probabilities_graph,\n",
    "            probabilities_distance,\n",
    "            repulsion_strength=self._repulsion_strength,\n",
    "        )   \n",
    "\n",
    "        return torch.mean(ce_loss)\n",
    "\n",
    "class DVILoss(nn.Module):\n",
    "    def __init__(self, umap_loss, recon_loss, temporal_loss, lambd1, lambd2, device):\n",
    "        super(DVILoss, self).__init__()\n",
    "        self.umap_loss = umap_loss\n",
    "        self.recon_loss = recon_loss\n",
    "        self.temporal_loss = temporal_loss\n",
    "        self.lambd1 = lambd1\n",
    "        self.lambd2 = lambd2\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, edge_to, edge_from, a_to, a_from, curr_model,probs):\n",
    "      \n",
    "        outputs = curr_model( edge_to, edge_from)\n",
    "        embedding_to, embedding_from = outputs[\"umap\"]\n",
    "        recon_to, recon_from = outputs[\"recon\"]\n",
    "\n",
    "        recon_l = self.recon_loss(edge_to, edge_from, recon_to, recon_from, a_to, a_from).to(self.device)\n",
    "        umap_l = self.umap_loss(embedding_to, embedding_from, probs)\n",
    "        temporal_l = self.temporal_loss(curr_model).to(self.device)\n",
    "\n",
    "        loss = umap_l + self.lambd1 * recon_l + self.lambd2 * temporal_l\n",
    "\n",
    "        return umap_l, umap_l, self.lambd1 *recon_l, self.lambd2 *temporal_l, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def remove_docstrings(code):\n",
    "    # 使用正则表达式匹配被 \"\"\" 包括的部分，并替换为空字符串\n",
    "    cleaned_code = re.sub(r'\"\"\".*?\"\"\"', '', code, flags=re.DOTALL)\n",
    "    cleaned_code = re.sub(r\"'''.*?'''\", '', cleaned_code, flags=re.DOTALL)\n",
    "    return cleaned_code\n",
    "\n",
    "def cosine_similarity_matrix(nl_features, code_features):\n",
    "    # 计算每个特征向量的范数\n",
    "    nl_norms = np.linalg.norm(nl_features, axis=1, keepdims=True)\n",
    "    code_norms = np.linalg.norm(code_features, axis=1, keepdims=True)\n",
    "    \n",
    "    # 计算点积\n",
    "    dot_product = np.dot(nl_features, code_features.T)\n",
    "    \n",
    "    # 计算余弦相似度矩阵\n",
    "    cosine_similarity = dot_product / (nl_norms * code_norms.T)\n",
    "    \n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_padding_intervals(tokenized_id_data):\n",
    "    \"\"\"\n",
    "    移除 tokenized_id_data 中所有 `[0,0]` 区间（除非它是开头的第一个区间）。\n",
    "\n",
    "    Args:\n",
    "    - tokenized_id_data (list of lists): 包含区间的列表，每个区间是一个长度为 2 的列表。\n",
    "\n",
    "    Returns:\n",
    "    - filtered_data (list of lists): 移除 `[0,0]` 填充数据后的区间列表。\n",
    "    \"\"\"\n",
    "    if isinstance(tokenized_id_data, np.ndarray):\n",
    "        tokenized_id_data = tokenized_id_data.tolist()  # 将 NumPy 数组转换为列表\n",
    "    # 处理的结果列表\n",
    "    filtered_data = []\n",
    "\n",
    "    # 保留开头的 `[0,0]` 区间（如果存在）\n",
    "    if tokenized_id_data and tokenized_id_data[0] == [0,0]:\n",
    "        filtered_data.append([0,0])\n",
    "        start_index = 1  # 从第二个元素开始检查\n",
    "    else:\n",
    "        start_index = 0\n",
    "\n",
    "    # 处理剩余的区间\n",
    "    for interval in tokenized_id_data[start_index:]:\n",
    "        if interval != [0,0]:  # 仅添加非 `[0,0]` 区间\n",
    "            filtered_data.append(interval)\n",
    "\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def load_loss_data(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "valid_code_path = \"/home/yiming/cophi/projects/fork/CoSQA_Plus/datasetBuild/dataset/gpt4o_augment_codebase_process.json\"\n",
    "code_dataset = []\n",
    "with open(valid_code_path, \"r\") as f:\n",
    "    try:\n",
    "        code_dataset = json.load(f)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing line in {valid_code_path}: {e}\")\n",
    "\n",
    "# 读取test_query_process.json文件 \n",
    "test_query_path = \"/home/yiming/cophi/projects/fork/CoSQA_Plus/datasetBuild/dataset/test_query_process.json\"\n",
    "comment_dataset = []\n",
    "with open(test_query_path, \"r\") as f:\n",
    "    try:\n",
    "        comment_dataset = json.load(f)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing {test_query_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# 文件路径\n",
    "json_file_path = '/home/yiming/cophi/training_dynamic/features/only_aa_labeled_multi_epochs_cls_cosqa/cosqa_tokenized_code_tokens.json'\n",
    "\n",
    "\n",
    "# 读取JSON文件\n",
    "with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "    code_tokens_data = json.load(f)\n",
    "\n",
    "# 文件路径\n",
    "json_file_path = '/home/yiming/cophi/training_dynamic/features/only_aa_labeled_multi_epochs_cls_cosqa/cosqa_tokenized_nl_tokens.json'\n",
    "\n",
    "\n",
    "# 读取JSON文件\n",
    "with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "    nl_tokens_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ind = 0\n",
    "convert_idx = 15633\n",
    "convert_idx_code = 7013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query idx is at position 1108 in comment_dataset\n"
     ]
    }
   ],
   "source": [
    "query_idx = None\n",
    "for i, item in enumerate(comment_dataset):\n",
    "    if item['query-idx'] == convert_idx:\n",
    "        query_idx = i\n",
    "        break\n",
    "print(f\"Query idx is at position {query_idx} in comment_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "for i in range(1, 2):\n",
    "    source_file = f'/home/yiming/cophi/training_dynamic/features/only_aa_labeled_multi_epochs/Epoch_{i}/cosqa_nl_tokens_curr_retri.npy'\n",
    "    destination_file = f'/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp_2/dataset/features/nl_tokens_{i}.npy'\n",
    "    shutil.copyfile(source_file, destination_file)\n",
    "for i in range(1, 2):\n",
    "    source_file = f'/home/yiming/cophi/training_dynamic/features/only_aa_labeled_multi_epochs/Epoch_{i}/cosqa_code_tokens_curr_retri.npy'\n",
    "    destination_file = f'/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp_2/dataset/features/code_tokens_{i}.npy'\n",
    "    shutil.copyfile(source_file, destination_file)\n",
    "    \n",
    "for i in range(1, 2):\n",
    "    source_file = f'/home/yiming/cophi/training_dynamic/features/only_aa_labeled_multi_epochs/Epoch_{i}/cosqa_nl_attention_curr_retri.npy'\n",
    "    destination_file = f'/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp_2/dataset/features/nl_attention_{i}.npy'\n",
    "    shutil.copyfile(source_file, destination_file)\n",
    "for i in range(1, 2):\n",
    "    source_file = f'/home/yiming/cophi/training_dynamic/features/only_aa_labeled_multi_epochs/Epoch_{i}/cosqa_code_attention_curr_retri.npy'\n",
    "    destination_file = f'/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp_2/dataset/features/code_attention_{i}.npy'\n",
    "    shutil.copyfile(source_file, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 文件路径\n",
    "nl_tokens_paths = [f'/home/yiming/cophi/training_dynamic/features/only_aa_labeled_multi_epochs/Epoch_{i}/cosqa_nl_tokens_curr_retri.npy' for i in range(1, 2)]\n",
    "code_tokens_paths = [f'/home/yiming/cophi/training_dynamic/features/only_aa_labeled_multi_epochs/Epoch_{i}/cosqa_code_tokens_curr_retri.npy' for i in range(1, 2)]\n",
    "\n",
    "# 读取nl_tokens.npy\n",
    "all_nl_tokens_list = []\n",
    "for path in nl_tokens_paths:\n",
    "    all_nl_tokens_list.append(np.load(path))\n",
    "\n",
    "# 读取code_tokens.npy \n",
    "all_code_tokens_list = []\n",
    "for path in code_tokens_paths:\n",
    "    all_code_tokens_list.append(np.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文件路径\n",
    "code_attention_paths = [f'/home/yiming/cophi/training_dynamic/features/only_aa_labeled_multi_epochs/Epoch_{i}/cosqa_code_attention_curr_retri.npy' for i in range(1, 2)]\n",
    "nl_attention_paths = [f'/home/yiming/cophi/training_dynamic/features/only_aa_labeled_multi_epochs/Epoch_{i}/cosqa_nl_attention_curr_retri.npy' for i in range(1, 2)]\n",
    "\n",
    "# 读取code attention features\n",
    "code_attention_features = []\n",
    "for path in code_attention_paths:\n",
    "    code_attention_features.append(np.load(path))\n",
    "\n",
    "# 读取nl attention features\n",
    "nl_attention_features = []\n",
    "for path in nl_attention_paths:\n",
    "    nl_attention_features.append(np.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_data = code_tokens_data[convert_idx_code]\n",
    "comment_data = nl_tokens_data[query_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理完成！\n"
     ]
    }
   ],
   "source": [
    "output_dir = '/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp_2/dataset/sample'\n",
    "\n",
    "# 确保输出目录存在\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 遍历列表的每一项\n",
    "for i, token_list in enumerate(comment_data):\n",
    "   \n",
    "    # 生成输出文件路径\n",
    "    output_file_path = os.path.join(output_dir, f'text_{i}.txt')\n",
    "    \n",
    "    # 保存到文件中，去除G点符号并加上序号\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as f_out:\n",
    "        token_str = str(comment_data[i]).replace('Ġ', '')\n",
    "        f_out.write(f\"{i}: {token_str}\")\n",
    "    # 找到</s>的位置，并保留其之前的部分\n",
    "    if '</s>' == token_list:\n",
    "        comment_length = i\n",
    "        break\n",
    "\n",
    "print(\"处理完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理完成！\n"
     ]
    }
   ],
   "source": [
    "output_dir = '/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp_2/dataset/sample/'\n",
    "\n",
    "# 确保输出目录存在\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 遍历列表的每一项\n",
    "for i, token_list in enumerate(code_data):\n",
    "   \n",
    "    # 生成输出文件路径\n",
    "    output_file_path = os.path.join(output_dir, f'text_{i+comment_length+1}.txt')\n",
    "    \n",
    "    # 保存到文件中，去除G点符号并加上序号\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as f_out:\n",
    "        token_str = str(code_data[i]).replace('Ġ', '')\n",
    "        f_out.write(f\"{i}: {token_str}\")\n",
    "    # 找到</s>的位置，并保留其之前的部分\n",
    "    if '</s>' == token_list:\n",
    "        code_length = i\n",
    "        break\n",
    "\n",
    "print(\"处理完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create labels\n",
    "labels = [0]*comment_length + [1]*code_length\n",
    "\n",
    "# Save labels to file\n",
    "output_dir = '/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp_2/dataset/label/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, 'labels.npy')\n",
    "np.save(output_path, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp_2/dataset'\n",
    "code_text = '<s> ' + code_dataset[convert_idx_code]['code']\n",
    "comment_text = '<s> ' + comment_dataset[query_idx]['query']\n",
    "# Create dictionary with the required data\n",
    "data_dict = {\n",
    "    'code': code_text,  # Original code text from training dataset\n",
    "    'docstring': comment_text,  # Original docstring text from training dataset\n",
    "    'code_tokens': code_data[:code_length],  # Code tokens after truncation\n",
    "    'comment_tokens': comment_data[:comment_length]  # Comment tokens after truncation\n",
    "}\n",
    "\n",
    "# Save to full_text.json\n",
    "output_path = os.path.join(output_dir, 'full_text.json')\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(data_dict, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 data shape: (49, 768)\n"
     ]
    }
   ],
   "source": [
    "# 获取 n 和 m\n",
    "n = comment_length\n",
    "m = code_length\n",
    "\n",
    "# 对每个epoch分别处理\n",
    "for epoch in range(1, 2):\n",
    "    # 读取当前epoch的nl_tokens和code_tokens\n",
    "    nl_tokens = all_nl_tokens_list[epoch-1][data_ind][:n]\n",
    "    code_tokens = all_code_tokens_list[epoch-1][data_ind][:m]\n",
    "    \n",
    "    # nl_tokens[0] = nl_cls_tokens[comment_id]\n",
    "    # code_tokens[0] = code_cls_tokens[data_ind]\n",
    "    \n",
    "    # 拼接两部分数据\n",
    "    combined_data = np.concatenate((nl_tokens, code_tokens))\n",
    "    print(f\"Epoch {epoch} data shape:\", combined_data.shape)\n",
    "    \n",
    "    # 检查并创建保存目录\n",
    "    output_dir = f'/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp_2/Model/Epoch_{epoch}'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # 保存到对应epoch的目录\n",
    "    output_path = os.path.join(output_dir, 'train_data.npy')\n",
    "    np.save(output_path, combined_data)\n",
    "    # print(f\"Epoch {epoch} 数据已保存到 {output_path}\")\n",
    "    # Save to visualization directory\n",
    "    visualize_dir = f'/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp_2/visualize/DVI/high_dim'\n",
    "    if not os.path.exists(visualize_dir):\n",
    "        os.makedirs(visualize_dir)\n",
    "    visualize_output_path = os.path.join(visualize_dir, f'train_data_{epoch}.npy')\n",
    "    np.save(visualize_output_path, combined_data)\n",
    "    # print(f\"Epoch {epoch} 数据已保存到 {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 生成从0到m-1的索引\n",
    "indices = list(range(m))\n",
    "\n",
    "# 为每个epoch创建并保存索引\n",
    "for epoch in range(1, 2):\n",
    "    # 生成当前epoch的输出路径\n",
    "    output_dir = f'/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp_2'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    index_output_path = os.path.join(output_dir, 'code_index.json')\n",
    "    \n",
    "    # 将索引保存到index.json中\n",
    "    with open(index_output_path, 'w', encoding='utf-8') as f_out:\n",
    "        json.dump(indices, f_out, ensure_ascii=False, indent=4)\n",
    "        \n",
    "    # print(f\"索引已保存到 {index_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成从0到n-1的索引\n",
    "indices = list(range(n))\n",
    "\n",
    "# 为每个epoch创建并保存索引\n",
    "for epoch in range(1, 2):\n",
    "    # 生成当前epoch的输出路径\n",
    "    output_dir = f'/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp_2'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    data_index_output_path = os.path.join(output_dir, 'comment_index.json')\n",
    "    \n",
    "    # 将索引保存到data_index.json中\n",
    "    with open(data_index_output_path, 'w', encoding='utf-8') as f_out:\n",
    "        json.dump(indices, f_out, ensure_ascii=False, indent=4)\n",
    "        \n",
    "    # print(f\"索引已保存到 {data_index_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成从0到n+m-1的索引\n",
    "indices = list(range(len(combined_data)))\n",
    "\n",
    "# 为每个epoch创建并保存索引\n",
    "for epoch in range(1, 2):\n",
    "    # 生成当前epoch的输出路径\n",
    "    output_dir = f'/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp_2/Model/Epoch_{epoch}'\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    index_output_path = os.path.join(output_dir, 'index.json')\n",
    "    \n",
    "    # 将索引保存到index.json中\n",
    "    with open(index_output_path, 'w', encoding='utf-8') as f_out:\n",
    "        json.dump(indices, f_out, ensure_ascii=False, indent=4)\n",
    "        \n",
    "    # print(f\"索引已保存到 {index_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 初始化存储所有epoch数据的列表\n",
    "all_intra_comment_sims = []\n",
    "all_intra_code_sims = []\n",
    "all_inter_comment_code_sims = []\n",
    "all_inter_code_comment_sims = []\n",
    "\n",
    "# 对每个epoch进行处理\n",
    "for epoch in range(1, 2):\n",
    "    # 读取数据\n",
    "    data_path = f'/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp_2/Model/Epoch_{epoch}/train_data.npy'\n",
    "    data = np.load(data_path)\n",
    "\n",
    "    # 读取 comment token 长度\n",
    "    data_index_path = f'/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp_2/comment_index.json'\n",
    "    with open(data_index_path, 'r') as f:\n",
    "        comment_length = len(json.load(f))\n",
    "\n",
    "    # 将数据分为前半部分的comment和后半部分的code\n",
    "    comments = data[:comment_length]  # 前半部分是comment\n",
    "    code_tokens = data[comment_length:]  # 后半部分是code\n",
    "\n",
    "    # 计算相似度函数（使用余弦相似度）\n",
    "    def compute_similarity(tokens_a, tokens_b):\n",
    "        return cosine_similarity(tokens_a, tokens_b)\n",
    "\n",
    "    # intra 相似度计算\n",
    "    intra_comment_sim = compute_similarity(comments, comments)\n",
    "    intra_code_sim = compute_similarity(code_tokens, code_tokens)\n",
    "\n",
    "    # inter 相似度计算\n",
    "    inter_comment_code_sim = compute_similarity(comments, code_tokens)\n",
    "    inter_code_comment_sim = compute_similarity(code_tokens, comments)\n",
    "\n",
    "    # 获取前 k 个最近邻\n",
    "    k = 10  # 假设我们需要前 5 个最近邻\n",
    "\n",
    "    # intra 计算\n",
    "    def get_intra_neighbors(sim_matrix, k, offset=0):\n",
    "        neighbors = []\n",
    "        for i in range(len(sim_matrix)):\n",
    "            # 获取当前样本对其他样本的相似度排序\n",
    "            sorted_indices = np.argsort(-sim_matrix[i])\n",
    "            # 如果样本数量不足k个，用自身的索引补齐\n",
    "            if len(sorted_indices) < k:\n",
    "                needed = k - len(sorted_indices)\n",
    "                neighbors.append(np.concatenate([\n",
    "                    sorted_indices + offset,\n",
    "                    np.array([i + offset] * needed)\n",
    "                ]))\n",
    "            else:\n",
    "                neighbors.append(sorted_indices[:k] + offset)\n",
    "        return np.array(neighbors)\n",
    "\n",
    "    intra_comment_neighbors = get_intra_neighbors(intra_comment_sim, k)\n",
    "    intra_code_neighbors = get_intra_neighbors(intra_code_sim, k, comment_length)\n",
    "\n",
    "    # inter 计算 - 应该使用专门的函数处理comment到code的映射\n",
    "    def get_comment_to_code_neighbors(sim_matrix, k, code_offset):\n",
    "        neighbors = []\n",
    "        for i in range(len(sim_matrix)):\n",
    "            # 获取当前注释对所有代码的相似度排序\n",
    "            sorted_indices = np.argsort(-sim_matrix[i])\n",
    "            # 将代码的索引加上offset以对应实际位置\n",
    "            neighbors.append(sorted_indices[:k] + code_offset)\n",
    "        return np.array(neighbors)\n",
    "\n",
    "    inter_comment_neighbors = get_comment_to_code_neighbors(inter_comment_code_sim, k, comment_length)  # comment 对 code 的相似度\n",
    "    \n",
    "    def get_code_to_comment_neighbors(sim_matrix, k, comment_length):\n",
    "        neighbors = []\n",
    "        for i in range(len(sim_matrix)):\n",
    "            # 获取当前代码对所有注释的相似度排序\n",
    "            sorted_indices = np.argsort(-sim_matrix[i])\n",
    "            # 如果注释数量不足k个，用代码自身的索引补齐\n",
    "            if len(sorted_indices) < k:\n",
    "                needed = k - len(sorted_indices)\n",
    "                neighbors.append(np.concatenate([\n",
    "                    sorted_indices,\n",
    "                    np.array([i + comment_length] * needed)\n",
    "                ]))\n",
    "            else:\n",
    "                neighbors.append(sorted_indices[:k])\n",
    "        return np.array(neighbors)\n",
    "\n",
    "    inter_code_neighbors = get_code_to_comment_neighbors(inter_code_comment_sim, k, comment_length)\n",
    "\n",
    "    # 拼接 intra 和 inter 结果\n",
    "    intra_neighbors = np.concatenate([intra_comment_neighbors, intra_code_neighbors], axis=0)\n",
    "    inter_neighbors = np.concatenate([inter_comment_neighbors, inter_code_neighbors], axis=0)\n",
    "\n",
    "    # 将当前epoch的结果添加到列表中\n",
    "    all_intra_comment_sims.append(intra_comment_sim)\n",
    "    all_intra_code_sims.append(intra_code_sim)\n",
    "    all_inter_comment_code_sims.append(inter_comment_code_sim)\n",
    "    all_inter_code_comment_sims.append(inter_code_comment_sim)\n",
    "\n",
    "    # 保存每个epoch的邻居信息\n",
    "    intra_save_dir = '/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp_2/dataset/intra_similarity'\n",
    "    inter_save_dir = '/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp_2/dataset/inter_similarity'\n",
    "    \n",
    "    import os\n",
    "    if not os.path.exists(intra_save_dir):\n",
    "        os.makedirs(intra_save_dir)\n",
    "    if not os.path.exists(inter_save_dir):\n",
    "        os.makedirs(inter_save_dir)\n",
    "\n",
    "\n",
    "    # 保存邻居信息\n",
    "    np.save(os.path.join(intra_save_dir, f'{epoch}.npy'), intra_neighbors)\n",
    "    np.save(os.path.join(inter_save_dir, f'{epoch}.npy'), inter_neighbors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3 style='margin:0'>Epoch 1</h3><h4 style='margin:0'>Comment:</h4><pre><span style=\"font-size: 11.042208909988403px;\">check</span> <span style=\"font-size: 16.0px;\">if</span> <span style=\"font-size: 9.361161947250366px;\">env</span> <span style=\"font-size: 9.036975026130676px;\">exists</span> <span style=\"font-size: 8.0px;\">python</span></pre><h4 style='margin:0'>Code:</h4><pre><span style=\"font-size: 12.03885269165039px;\">def</span> <span style=\"font-size: 16.0px;\">check</span><span style=\"font-size: 11.304269313812256px;\">_</span><span style=\"font-size: 14.405183792114258px;\">env</span><span style=\"font-size: 12.400076866149902px;\">(</span><span style=\"font-size: 9.811145186424255px;\">*</span><span style=\"font-size: 11.306249380111694px;\">args</span><span style=\"font-size: 11.851297378540039px;\">)</span><span style=\"font-size: 10.59116506576538px;\">:</span><br>    <span style=\"font-size: 8.68073284626007px;\">for</span> <span style=\"font-size: 8.883885741233826px;\">arg</span> <span style=\"font-size: 8.954897403717041px;\">in</span> <span style=\"font-size: 10.531983613967896px;\">args</span><span style=\"font-size: 9.118532657623291px;\">:</span><br>        <span style=\"font-size: 8.30709195137024px;\">if</span> <span style=\"font-size: 8.433274745941162px;\">arg</span> <span style=\"font-size: 8.170887723565102px;\">not</span> <span style=\"font-size: 8.455259412527084px;\">in</span> <span style=\"font-size: 9.877726197242737px;\">os</span><span style=\"font-size: 8.38703829050064px;\">.</span><span style=\"font-size: 8.79021006822586px;\">en</span><span style=\"font-size: 8.975635409355164px;\">viron</span><span style=\"font-size: 8.368050813674927px;\">:</span><br>            <span style=\"font-size: 8.84444111585617px;\">raise</span> <span style=\"font-size: 8.392615884542465px;\">Value</span><span style=\"font-size: 8.227878674864769px;\">Error</span><span style=\"font-size: 8.308373004198074px;\">(</span><span style=\"font-size: 8.326575964689255px;\">\"</span><span style=\"font-size: 9.550669431686401px;\">Environment</span> <span style=\"font-size: 9.458070397377014px;\">variable</span> <span style=\"font-size: 8.050682824105024px;\">'</span><span style=\"font-size: 8.036665994673967px;\">{</span><span style=\"font-size: 8.002938315737993px;\">}</span><span style=\"font-size: 8.015062738209963px;\">'</span> <span style=\"font-size: 9.706308364868164px;\">required</span><span style=\"font-size: 8.2912238240242px;\">\"</span><span style=\"font-size: 8.0px;\">.</span><span style=\"font-size: 8.1649751663208px;\">format</span><span style=\"font-size: 8.075467206537724px;\">(</span><span style=\"font-size: 8.42662838101387px;\">arg</span><span style=\"font-size: 8.105295516550541px;\">)</span><span style=\"font-size: 8.776009380817413px;\">)</span></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import deque\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import time\n",
    "\n",
    "# 处理code部分\n",
    "code_snippet = remove_docstrings(code_dataset[convert_idx_code][\"code\"])\n",
    "token_list2 = code_tokens_data[convert_idx_code][1:]\n",
    "token_list1 = nl_tokens_data[query_idx][1:]\n",
    "# Get docstring and remove parameter descriptions\n",
    "doc_snippet = comment_dataset[query_idx][\"query\"].split(\"\\n\")[0]\n",
    "# Remove any parts of code_snippet that appear in doc_snippet\n",
    "doc_words = set(doc_snippet.lower().split())\n",
    "code_lines = code_snippet.split('\\n')\n",
    "filtered_code_lines = []\n",
    "\n",
    "for line in code_lines:\n",
    "    # Skip line if it contains too many words from docstring\n",
    "    line_words = set(line.lower().split())\n",
    "    overlap = len(line_words.intersection(doc_words))\n",
    "    if overlap < len(line_words) / 2:  # Keep line if less than 50% overlap\n",
    "        filtered_code_lines.append(line)\n",
    "\n",
    "code_snippet = '\\n'.join(filtered_code_lines)\n",
    "\n",
    "# 对1-50 epoch分别计算\n",
    "for epoch in range(1, 2):\n",
    "    # 清除上一次的输出\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    # 处理comment部分\n",
    "    array = nl_attention_features[epoch-1][data_ind]  # 从list中获取对应epoch的数据\n",
    "    array = array[1:comment_length]\n",
    "    \n",
    "    normalized_contributions = (array - array.min()) / (array.max() - array.min())\n",
    "    tokens_with_contributions = deque([(token.replace(\"Ġ\", \"\"), contrib) for token, contrib in zip(token_list1, normalized_contributions)])\n",
    "\n",
    "    code_attention_feature = code_attention_features[epoch-1][data_ind][1:code_length]\n",
    "    code_normalized_contributions = (code_attention_feature - code_attention_feature.min()) / (code_attention_feature.max() - code_attention_feature.min())\n",
    "    code_tokens_with_contributions = deque([(token.replace(\"Ġ\", \"\"), contrib) for token, contrib in zip(token_list2, code_normalized_contributions)])\n",
    "\n",
    "    # 生成HTML输出\n",
    "    html_string = f\"<h3 style='margin:0'>Epoch {epoch}</h3>\"\n",
    "    \n",
    "    # Comment部分\n",
    "    html_string += \"<h4 style='margin:0'>Comment:</h4><pre>\"\n",
    "    buffer = \"\"\n",
    "    current_index = 0\n",
    "    for char in doc_snippet:\n",
    "        if char == \"\\n\":\n",
    "            html_string += buffer + \"<br>\"\n",
    "            buffer = \"\"\n",
    "        elif tokens_with_contributions:\n",
    "            token, contrib = tokens_with_contributions[0]\n",
    "            buffer += char\n",
    "            if buffer == token:\n",
    "                font_size = 8 + (16 - 8) * contrib\n",
    "                html_string += f'<span style=\"font-size: {font_size}px;\">{buffer}</span>'\n",
    "                buffer = \"\"\n",
    "                tokens_with_contributions.popleft()\n",
    "                current_index += 1\n",
    "            elif not token.startswith(buffer):\n",
    "                html_string += buffer[0]\n",
    "                buffer = buffer[1:]\n",
    "        else:\n",
    "            html_string += char\n",
    "    html_string += buffer + \"</pre>\"\n",
    "\n",
    "    # Code部分\n",
    "    html_string += \"<h4 style='margin:0'>Code:</h4><pre>\"\n",
    "    buffer = \"\"\n",
    "    current_index = 0\n",
    "    for char in code_snippet:\n",
    "        if char == \"\\n\":\n",
    "            html_string += buffer + \"<br>\"\n",
    "            buffer = \"\"\n",
    "        elif code_tokens_with_contributions:\n",
    "            token, contrib = code_tokens_with_contributions[0]\n",
    "            buffer += char\n",
    "            if buffer == token:\n",
    "                font_size = 8 + (16 - 8) * contrib\n",
    "                html_string += f'<span style=\"font-size: {font_size}px;\">{buffer}</span>'\n",
    "                buffer = \"\"\n",
    "                code_tokens_with_contributions.popleft()\n",
    "                current_index += 1\n",
    "            elif not token.startswith(buffer):\n",
    "                html_string += buffer[0]\n",
    "                buffer = buffer[1:]\n",
    "        else:\n",
    "            html_string += char\n",
    "    html_string += buffer + \"</pre>\"\n",
    "\n",
    "    # 显示结果\n",
    "    display(HTML(html_string))\n",
    "    \n",
    "    # 添加延迟以便观察动画效果\n",
    "    time.sleep(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预设20种颜色\n",
    "high_contrast_colors = [\n",
    "    \"#FF0000\", \"#00FF00\", \"#0000FF\", \"#FFA500\", \"#FF00FF\", \n",
    "    \"#00FFFF\", \"#800000\", \"#008000\", \"#000080\", \"#808000\",\n",
    "    \"#FF4500\", \"#FFD700\", \"#FF6347\", \"#FF69B4\", \"#FF1493\",\n",
    "    \"#FF00FF\", \"#FF8C00\", \"#FFA07A\", \"#FFB6C1\", \"#FFDAB9\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 768)\n",
      "发现 8 个聚类群组\n",
      "\n",
      "群组 1 (大小: 6):\n",
      "  代码 token 索引: [0, 1, 2, 4, 7, 8]\n",
      "  注释 token 索引: []\n",
      "\n",
      "群组 2 (大小: 3):\n",
      "  代码 token 索引: [3, 28, 29]\n",
      "  注释 token 索引: []\n",
      "\n",
      "群组 3 (大小: 2):\n",
      "  代码 token 索引: [6, 12]\n",
      "  注释 token 索引: []\n",
      "\n",
      "群组 4 (大小: 1):\n",
      "  代码 token 索引: [5]\n",
      "  注释 token 索引: []\n",
      "\n",
      "群组 5 (大小: 1):\n",
      "  代码 token 索引: [18]\n",
      "  注释 token 索引: []\n",
      "\n",
      "群组 6 (大小: 1):\n",
      "  代码 token 索引: [34]\n",
      "  注释 token 索引: []\n",
      "\n",
      "群组 7 (大小: 1):\n",
      "  代码 token 索引: []\n",
      "  注释 token 索引: [0]\n",
      "\n",
      "群组 8 (大小: 1):\n",
      "  代码 token 索引: []\n",
      "  注释 token 索引: [1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "selected_epoch = 1\n",
    "\n",
    "# 读取 comment token 长度\n",
    "data_index_path = f'/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp_2/comment_index.json'\n",
    "with open(data_index_path, 'r') as f:\n",
    "    comment_length = len(json.load(f))\n",
    "\n",
    "data_index_path = f'/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp_2/code_index.json'\n",
    "with open(data_index_path, 'r') as f:\n",
    "    code_length = len(json.load(f))\n",
    "\n",
    "# Load train data for the selected epoch\n",
    "output_dir = f'/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp_2/visualize/DVI/high_dim'\n",
    "train_data_path = os.path.join(output_dir, f'train_data_{selected_epoch}.npy')\n",
    "train_data = np.load(train_data_path)\n",
    "\n",
    "# Split train data based on comment length and code length\n",
    "comment_vectors = train_data[:comment_length]\n",
    "code_vectors = train_data[comment_length:]\n",
    "\n",
    "# 设置相似度阈值\n",
    "similarity_threshold = 0.7  # 用于判断相似性\n",
    "\n",
    "# 加载代码和注释的注意力数据\n",
    "code_attention = code_attention_features[selected_epoch-1][data_ind][1:code_length]\n",
    "comment_attention = nl_attention_features[selected_epoch-1][data_ind][1:comment_length]\n",
    "\n",
    "# 计算代码和注释的平均注意力\n",
    "avg_code_attention = np.mean(code_attention)\n",
    "avg_comment_attention = np.mean(comment_attention)\n",
    "\n",
    "# 筛选高于平均注意力的索引\n",
    "filtered_code_indices = np.where(code_attention > avg_code_attention)[0]\n",
    "filtered_comment_indices = np.where(comment_attention > avg_comment_attention)[0]\n",
    "\n",
    "# 提取对应的代码和注释向量\n",
    "filtered_code_vectors = code_vectors[1:][filtered_code_indices]\n",
    "filtered_comment_vectors = comment_vectors[1:][filtered_comment_indices]\n",
    "\n",
    "# 合并代码和注释向量作为聚类数据\n",
    "combined_vectors = np.vstack((filtered_code_vectors, filtered_comment_vectors))\n",
    "print(combined_vectors.shape)\n",
    "\n",
    "# 计算余弦相似度矩阵\n",
    "similarity_matrix = cosine_similarity(combined_vectors)\n",
    "\n",
    "# 将相似度转换为距离（确保相似度不超出范围）\n",
    "distance_matrix = 1 - similarity_matrix\n",
    "\n",
    "# 将所有负值截断为 0，避免数值误差导致问题\n",
    "distance_matrix = np.clip(distance_matrix, 0, None)\n",
    "\n",
    "clustering = DBSCAN(eps=1-similarity_threshold, min_samples=1, metric='precomputed').fit(distance_matrix)\n",
    "\n",
    "# 获取聚类标签\n",
    "cluster_labels = clustering.labels_\n",
    "\n",
    "# 记录索引的映射（用于恢复原始索引）\n",
    "original_indices = np.concatenate((filtered_code_indices, filtered_comment_indices + code_length))\n",
    "\n",
    "# 存储聚类结果\n",
    "clusters = {}\n",
    "for idx, label in enumerate(cluster_labels):\n",
    "    if label == -1:\n",
    "        continue  # 跳过噪声点\n",
    "    if label not in clusters:\n",
    "        clusters[label] = {'code_indices': set(), 'comment_indices': set()}\n",
    "    \n",
    "    original_idx = original_indices[idx]\n",
    "    if original_idx < code_length:\n",
    "        clusters[label]['code_indices'].add(original_idx)\n",
    "    else:\n",
    "        clusters[label]['comment_indices'].add(original_idx - code_length)\n",
    "\n",
    "# 按群组大小排序\n",
    "sorted_clusters = sorted(clusters.items(), key=lambda x: len(x[1]['code_indices']) + len(x[1]['comment_indices']), reverse=True)\n",
    "\n",
    "# 打印结果\n",
    "print(f\"发现 {len(sorted_clusters)} 个聚类群组\")\n",
    "for group_idx, (label, group) in enumerate(sorted_clusters):\n",
    "    print(f\"\\n群组 {group_idx + 1} (大小: {len(group['code_indices']) + len(group['comment_indices'])}):\")\n",
    "    print(f\"  代码 token 索引: {sorted(list(group['code_indices']))}\")\n",
    "    print(f\"  注释 token 索引: {sorted(list(group['comment_indices']))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4 style='margin:0'>Comment:</h4><pre><span style=\"font-size: 11.810575723648071px; color: #800000;\">check</span><span style=\"color: #008000;\"> </span><span style=\"font-size: 14.67922830581665px; color: #008000;\">if</span><span style=\"color: black;\"> </span><span style=\"font-size: 10.837896347045898px; color: black;\">env</span><span style=\"color: black;\"> </span><span style=\"font-size: 10.650316953659058px; color: black;\">exists</span><span style=\"color: black;\"> </span><span style=\"font-size: 10.050307512283325px; color: black;\">python</span></pre><h4 style='margin:0'>Code:</h4><pre><span style=\"font-size: 12.087158203125px; color: #FF0000;\">def</span><span style=\"color: #FF0000;\"> </span><span style=\"font-size: 16.0px; color: #FF0000;\">check</span><span style=\"font-size: 11.361533164978027px; color: #FF0000;\">_</span><span style=\"font-size: 14.42463207244873px; color: #00FF00;\">env</span><span style=\"font-size: 12.443977355957031px; color: #FF0000;\">(</span><span style=\"font-size: 9.886617660522461px; color: #FFA500;\">*</span><span style=\"font-size: 11.363488912582397px; color: #0000FF;\">args</span><span style=\"font-size: 11.901890277862549px; color: #FF0000;\">)</span><span style=\"font-size: 10.657125234603882px; color: #FF0000;\">:</span><br><span style=\"color: black;\"> </span><span style=\"color: black;\"> </span><span style=\"color: black;\"> </span><span style=\"color: black;\"> </span><span style=\"font-size: 8.769990503787994px; color: black;\">for</span><span style=\"color: black;\"> </span><span style=\"font-size: 8.97066593170166px; color: black;\">arg</span><span style=\"color: black;\"> </span><span style=\"font-size: 9.040811657905579px; color: black;\">in</span><span style=\"color: #0000FF;\"> </span><span style=\"font-size: 10.598665475845337px; color: #0000FF;\">args</span><span style=\"font-size: 9.202451348304749px; color: black;\">:</span><br><span style=\"color: black;\"> </span><span style=\"color: black;\"> </span><span style=\"color: black;\"> </span><span style=\"color: black;\"> </span><span style=\"color: black;\"> </span><span style=\"color: black;\"> </span><span style=\"color: black;\"> </span><span style=\"color: black;\"> </span><span style=\"font-size: 8.400906085968018px; color: black;\">if</span><span style=\"color: black;\"> </span><span style=\"font-size: 8.525550127029419px; color: black;\">arg</span><span style=\"color: black;\"> </span><span style=\"font-size: 8.266362875699997px; color: black;\">not</span><span style=\"color: black;\"> </span><span style=\"font-size: 8.547266662120819px; color: black;\">in</span><span style=\"color: #FF00FF;\"> </span><span style=\"font-size: 9.952386617660522px; color: #FF00FF;\">os</span><span style=\"font-size: 8.479877471923828px; color: black;\">.</span><span style=\"font-size: 8.87813264131546px; color: black;\">en</span><span style=\"font-size: 9.061296701431274px; color: black;\">viron</span><span style=\"font-size: 8.461121588945389px; color: black;\">:</span><br><span style=\"color: black;\"> </span><span style=\"color: black;\"> </span><span style=\"color: black;\"> </span><span style=\"color: black;\"> </span><span style=\"color: black;\"> </span><span style=\"color: black;\"> </span><span style=\"color: black;\"> </span><span style=\"color: black;\"> </span><span style=\"color: black;\"> </span><span style=\"color: black;\"> </span><span style=\"color: black;\"> </span><span style=\"color: black;\"> </span><span style=\"font-size: 8.931702315807343px; color: black;\">raise</span><span style=\"color: black;\"> </span><span style=\"font-size: 8.485387086868286px; color: black;\">Value</span><span style=\"font-size: 8.32265880703926px; color: black;\">Error</span><span style=\"font-size: 8.402171522378922px; color: black;\">(</span><span style=\"font-size: 8.420152515172958px; color: black;\">\"</span><span style=\"font-size: 9.629318356513977px; color: #00FF00;\">Environment</span><span style=\"color: #00FF00;\"> </span><span style=\"font-size: 9.537848591804504px; color: #00FF00;\">variable</span><span style=\"color: black;\"> </span><span style=\"font-size: 8.147623851895332px; color: black;\">'</span><span style=\"font-size: 8.13377794623375px; color: black;\">{</span><span style=\"font-size: 8.100461579859257px; color: black;\">}</span><span style=\"font-size: 8.112438142299652px; color: black;\">'</span><span style=\"color: #00FFFF;\"> </span><span style=\"font-size: 9.783059239387512px; color: #00FFFF;\">required</span><span style=\"font-size: 8.385231465101242px; color: black;\">\"</span><span style=\"font-size: 8.097559094429016px; color: black;\">.</span><span style=\"font-size: 8.26052239537239px; color: black;\">format</span><span style=\"font-size: 8.172105982899666px; color: black;\">(</span><span style=\"font-size: 8.5189847946167px; color: black;\">arg</span><span style=\"font-size: 8.20157054066658px; color: black;\">)</span><span style=\"font-size: 8.864105105400085px; color: black;\">)</span></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "from collections import deque\n",
    "\n",
    "# Process code part\n",
    "code_snippet = remove_docstrings(code_dataset[convert_idx_code][\"code\"])\n",
    "token_list2 = code_tokens_data[convert_idx_code][1:]\n",
    "token_list1 = nl_tokens_data[query_idx][1:]\n",
    "\n",
    "# Get docstring and remove parameter descriptions\n",
    "doc_snippet = comment_dataset[query_idx][\"query\"].split(\"\\n\")[0]\n",
    "\n",
    "# Remove any parts of code_snippet that appear in doc_snippet\n",
    "doc_words = set(doc_snippet.lower().split())\n",
    "code_lines = code_snippet.split('\\n')\n",
    "filtered_code_lines = []\n",
    "\n",
    "for line in code_lines:\n",
    "    # Skip line if it contains too many words from docstring\n",
    "    line_words = set(line.lower().split())\n",
    "    overlap = len(line_words.intersection(doc_words))\n",
    "    if overlap < len(line_words) / 2:  # Keep line if less than 50% overlap\n",
    "        filtered_code_lines.append(line)\n",
    "\n",
    "code_snippet = '\\n'.join(filtered_code_lines)\n",
    "\n",
    "# Process comment part - using the similarity groups we defined earlier\n",
    "array = nl_attention_features[epoch-1][data_ind]  # Get data for current epoch\n",
    "array = array[1:]\n",
    "\n",
    "normalized_contributions = (array - array.min()) / (array.max() - array.min())\n",
    "tokens_with_contributions = deque([(token.replace(\"Ġ\", \"\"), contrib) for token, contrib in zip(token_list1, normalized_contributions)])\n",
    "\n",
    "code_attention_feature = code_attention_features[epoch-1][data_ind][1:]\n",
    "code_normalized_contributions = (code_attention_feature - code_attention_feature.min()) / (code_attention_feature.max() - code_attention_feature.min())\n",
    "code_tokens_with_contributions = deque([(token.replace(\"Ġ\", \"\"), contrib) for token, contrib in zip(token_list2, code_normalized_contributions)])\n",
    "\n",
    "# Use the similarity groups to assign colors\n",
    "# Each group contains {'codes': set(), 'comments': set()}\n",
    "color_map_comment = {}\n",
    "color_map_code = {}\n",
    "\n",
    "for group_idx, (label, group) in enumerate(sorted_clusters):\n",
    "    color = high_contrast_colors[group_idx % len(high_contrast_colors)]\n",
    "    for code_idx in group['code_indices']:\n",
    "        color_map_code[code_idx] = color\n",
    "    for comment_idx in group['comment_indices']:\n",
    "        color_map_comment[comment_idx] = color\n",
    "\n",
    "# Generate HTML output\n",
    "html_string = \"<h4 style='margin:0'>Comment:</h4><pre>\"\n",
    "buffer = \"\"\n",
    "current_index = 0\n",
    "for char in doc_snippet:\n",
    "    if char == \"\\n\":\n",
    "        html_string += buffer + \"<br>\"\n",
    "        buffer = \"\"\n",
    "    elif tokens_with_contributions:\n",
    "        token, contrib = tokens_with_contributions[0]\n",
    "        buffer += char\n",
    "        if buffer == token:\n",
    "            font_size = 8 + (16 - 8) * contrib\n",
    "            color = color_map_comment.get(current_index, \"black\")\n",
    "            html_string += f'<span style=\"font-size: {font_size}px; color: {color};\">{buffer}</span>'\n",
    "            buffer = \"\"\n",
    "            tokens_with_contributions.popleft()\n",
    "            current_index += 1\n",
    "        elif not token.startswith(buffer):\n",
    "            color = color_map_comment.get(current_index, \"black\")\n",
    "            html_string += f'<span style=\"color: {color};\">{buffer[0]}</span>'\n",
    "            buffer = buffer[1:]\n",
    "    else:\n",
    "        color = color_map_comment.get(current_index, \"black\")\n",
    "        html_string += f'<span style=\"color: {color};\">{char}</span>'\n",
    "html_string += buffer + \"</pre>\"\n",
    "\n",
    "# Code part\n",
    "html_string += \"<h4 style='margin:0'>Code:</h4><pre>\"\n",
    "buffer = \"\"\n",
    "current_index = 0\n",
    "for char in code_snippet:\n",
    "    if char == \"\\n\":\n",
    "        html_string += buffer + \"<br>\"\n",
    "        buffer = \"\"\n",
    "    elif code_tokens_with_contributions:\n",
    "        token, contrib = code_tokens_with_contributions[0]\n",
    "        buffer += char\n",
    "        if buffer == token:\n",
    "            font_size = 8 + (16 - 8) * contrib\n",
    "            color = color_map_code.get(current_index, \"black\")\n",
    "            html_string += f'<span style=\"font-size: {font_size}px; color: {color};\">{buffer}</span>'\n",
    "            buffer = \"\"\n",
    "            code_tokens_with_contributions.popleft()\n",
    "            current_index += 1\n",
    "        elif not token.startswith(buffer):\n",
    "            color = color_map_code.get(current_index, \"black\")\n",
    "            html_string += f'<span style=\"color: {color};\">{buffer[0]}</span>'\n",
    "            buffer = buffer[1:]\n",
    "    else:\n",
    "        color = color_map_code.get(current_index, \"black\")\n",
    "        html_string += f'<span style=\"color: {color};\">{char}</span>'\n",
    "html_string += buffer + \"</pre>\"\n",
    "\n",
    "# Display result\n",
    "display(HTML(html_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention sums by color group:\n",
      "\n",
      "Comment:\n",
      "\u001b[48;2;128;0;0m  \u001b[0m #800000: 0.1016\n",
      "\u001b[48;2;0;128;0m  \u001b[0m #008000: 0.1780\n",
      "\n",
      "Code:\n",
      "\u001b[48;2;255;0;0m  \u001b[0m #FF0000: 0.3450\n",
      "\u001b[48;2;0;255;0m  \u001b[0m #00FF00: 0.1251\n",
      "\u001b[48;2;0;0;255m  \u001b[0m #0000FF: 0.0778\n",
      "\u001b[48;2;255;165;0m  \u001b[0m #FFA500: 0.0246\n",
      "\u001b[48;2;255;0;255m  \u001b[0m #FF00FF: 0.0255\n",
      "\u001b[48;2;0;255;255m  \u001b[0m #00FFFF: 0.0233\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtcAAAF5CAYAAABUcAZeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAy9UlEQVR4nO3de7hWdZ3//+dbUOmgpsiogQoCOYooBR4oySLwVEA0HtBphMm+XvrVnHTGSTtYWX7z0GgzZT9zLi2oFAtTscFDHkgdDxxso4IiqJQgnoDUzBP6/v2x1t7dbjabG1g3m43Px3Xdl/f6rPVZ632vfW983Z/9WeuOzESSJEnS+tusowuQJEmSNhWGa0mSJKkihmtJkiSpIoZrSZIkqSKGa0mSJKkihmtJkiSpIoZrSRudiPjHiLilo+toFhHviYgbIuLFiPh1R9dTj4gYFhHzO7qODSUiMiL6bQR1TI+IL3Z0HZI6juFa2oRFxLERMSsi/hIRSyPixog4sKPrWpPM/GVmHtzRddQ4AtgB6J6ZR65uo4iYUIa8o1u1fysiftGqrdIQ1jpcZuZdmbl7VftvdazjI+LRiHg5Ip6NiGkRsVUjjtURImKniLi8/J15uXyt346I93VALVtFxEURsSgiXomIP0XElIjYf0PXIqk+hmtpExURpwM/AP4fRTDcBfgxMKYDy1qjiOja0TW0YVfgscxcuYbtxgPLgeMaX1LHiIiDKN5Tx2TmVsAewNUdW1V1ImI74F7gPcDQ8jWOBD4A9G3gcVd530fElsDtwEDgM8DWFOd7MnBYvfuRtIFlpg8fPjaxB7AN8BfgyHa22ZIifD9dPn4AbFmu+wSwGPh34DlgKfBZ4HDgMYoA+dWafX0LmEIRsl4GHgD2qVl/JvB4uW4eMLZm3QTgf4GLgWXAd8u2u8v1Ua57DngJeAjYq+Z1TgKeB/4IfB3YrGa/dwPfB1YATwKHtXM+9gCmA38G5gKjy/ZvA28Ab5bn9PjV9N8VeBv4B2AlsGPZfmir/nOAc4G3gNfKth+V2/498Lvy/M4HjqrZ/8+AS4D/Kc/j/UDfct2dQAKvlPs7uvlnuKbXt6Z9t/E6/w24rp3zOB34Yquf7901ywn8X2BBeazvUITWe8qf76+ALcpttwd+W9a8HLir+efbxnETOBV4AngBuJBiAGmLsu/Amm3/Dvgr0KON/XyX4j3W5nHKbT4KzAReLP/70bZef3n8r1O8N5+jeK9uU67rXdZ8PPAn4M42jvNFit+9963h9z2Bk8tz+mTZ9n+AheVrnwp8sNVxu66m5gkUv48/Kl/fo8CnOvrfNB8+OtOjwwvw4cNH9Q+KQLey9n+gbWxzDnBfGTR6lOHmO+W6T5T9zwY2L/9H/TxwJbAVMAB4FehTbv8tivB4RLn9v1GE2c3L9UcCHyzDxtEUIXCnct2E8lhfArpSjBhO4G/h+hBgNsXIYVCExOa+k4Dry5p6UwT/42v2+2ZZexfgJIoPEdHGudi8DCJfpQhjwymC3+41r+8Xazjn3wBmlM8fAv61Zt0q/Vk1hL4PeAr45/I8fJgiJO5Zrv8ZxYeP/cr1vwQm1/RPoF/N8icow3Udr6/dfbeqe1j5s/828DHKD2TtvK6Wn2VNnddTjMIOAF4HbgN2o/iwNA8YX277PeDSsv7Ny2Ov8vOr2e8dwHYUf6V5jL8Fxh8D59ds+y/ADavZz33At9v5OW9H8WHtn8pzdUy53L316we+UJ733YD3A78Bfl6u613WPKn82b+njWNNBn5Wx+97Unwo247i92d4+d75CMWH6B9ShnfqC9crgdPKc340RcjerqP/XfPho7M8nBYibZq6Ay9k+9MY/hE4JzOfy8znKcLSP9WsfxM4NzPfpPif/PbAf2bmy5k5lyIE7VOz/ezMnFJufxHQDTgAIDN/nZlPZ+bbmXk1xQjbfjV9n87MH2bmysx8tVWdb1KE57+nCFaPZObSiOgCjAPOKmtaBPxHq9fwx8z878x8C5gI7EQxRaa1AyjCz3mZ+UZm3k4xYnpMO+evteMoPnxQ/ndtp4Z8BliUmT8tz8MfgGsoPpg0uzYzZ5Q/118Cg+rcdz2vr659Z+ZdwOcogtv/AMvKOcFd6n2hwAWZ+VL5PnoYuCUzn8jMF4EbKT5YQPGz3wnYNTPfzGIeebaz3/Mzc3lm/oniLzHNr28icExERLn8T8DPV7OP7hSjxavzaWBBZv68/DldRTG6O6qNbf8RuKh8bX8BzgLGtZq68a3MfKWN9z0Uv3PPNC9ExKCI+HNEvNTGxarfK1/7q+Vxr8jMBzLz9fK4QyOidzuvq9ZzwA/Kc341xV9RPl1nX+ldz3AtbZqWAduvYf7lByn+XN3sj2Vbyz7KUArFSCXAszXrX6UIbM2ean6SmW9TTCv5IEBEHBcRTWUw+DOwF0VwWKVva2UQ/BHFtIXnIuKyiNi67L95G6+hZ83yMzX7+Wv5tLbmZh8EnirrXt2+VisiPgb0ofgQAkW4HhgRg+rpX9oV2L/5HJXn6R+BHWu2eabm+V9p+7W0pZ7XV/e+M/PGzBxFMVI6hmK0c20uzmz9Plrd++pCipHfWyLiiYg4cw37rX0ftbyfM/N+itf0iYj4e6AfxVSJtiyjCPSr0/r3pvlYbb1X2vod68o7P+Ct9r3fupbMbMrMD1B8uNmy1ba1+3nHcctgv2w1NbZlSasPMa3/bZDUDsO1tGm6l+LP7Z9tZ5unKQJds13KtnW1c/OTiNgM6AU8HRG7Av8NnELxp/MPUIxWRk3f9kYjycz/yszBwJ7Ah4AzKP7s/WYbr2HJOtT+NLBzWfe67Gs8xetpiohnKOYsN7dD26+vddtTwO8z8wM1j/dn5kl11tCe9X19bSr/EnEbxUV3e5XNrwDvrdlsx1U61r//lzPzXzNzN2A0cHpEfKqdLjvXPG/9fp4IfJ5i1HpKZr62mn3cCoxtda5qtf69aT5WW+eyrd+xlbzzw0R77/3bgIPrvEtJ7X7ecdyyf/eyxlfK5vZ+Rj1rRvmb616ffxukdxXDtbQJKv+8fjZwSUR8NiLeGxGbR8RhEXFBudlVwNcjokdEbF9u/4vV7bMOgyPic+Vo+Zcpwv19FPNJk2LONhHxz/wtiK1RROwbEftHxOYUweA14O1yVP1XwLnl7cp2BU5fx9fQPLL57+V5+gTFn/knt9eprK8bcBRwAsVUiubHl4Bjy/PxLNC7VWB7lmIubrPfAh+KiH8qa9i8fO171PkaWu+vktfXWkSMiYhxEbFtFPYDDqL4WQM0AZ8r33P9KC7YWycR8ZmI6FcGvRcpLgJ9u50uZ5R17Uwxr7r2Lia/AMZSBOxJ7ezjIor54BPL9xQR0bOc+rI3MI3i53RsRHQtb7u4J8XPr7WrgNMiok9EvJ/iLitXr2G6Vq1JFFNUro2IvSKiS/l+G7KGflcB/1xOI9myPO79mbmonAK2BPh8ub8vsOpdUP4OOLV8rxxJcZ3DtDprlt71DNfSJioz/4MibH6dItg+RTF6fF25yXeBWcCDFBfgPVC2ravrKS5+ar7Y63PlnM15FHOh76UIgAMp7kZQr60pRr5XUPx5ehnFdAEoAuwrFHeIuJtiOsYVa1t4Zr5BETYPoxgR/zFwXGY+Wkf3z1JMZZiUmc80P8o6ulJcXNr8xTPLIuKB8vl/AkdExIqI+K/MfBk4mGIe+dMU0zTOZ9U//6/OtygC4Z8j4qgKX19rKyguEl1AcXePXwAXZuYvy/UXU9wd5VmK0eJftrWTOvWnGEn+C8X758eZeUc7219PcfFrE8V88MubV2TmUxTv8aS460ibMnM5xd1A3gTuj4iXKUaQXwQWZuYyivnx/0rxXvx34DOZ+UIbu7uCYm73nRQX+L5G8Z6tSzm6/kmK6xv+h+J8zwf2pfhAt7p+t1JcYHsNRTjvS/G+avZ/KP76s4ziotJ7Wu3ifopz/wLFnW2OKF+3pDpE+9eGSNKaRcS3KO5U8fmOrkVanYi4guLi2a93dC0bq4iYQHHnkI3+y6akjZU3m5ckbfLKO2V8jr/diUSSGsJpIZKkTVpEfIfiItoLM/PJjq5H0qbNaSGSJElSRRy5liRJkipiuJYkSZIqsslc0Lj99ttn7969O7oMSZIkbeJmz579Qmb2aGvdJhOue/fuzaxZszq6DEmSJG3iIuKPq1vntBBJkiSpIoZrSZIkqSKGa0mSJKkim8yca0mSpCq8+eabLF68mNdee62jS1EH69atG7169WLzzTevu4/hWpIkqcbixYvZaqut6N27NxHR0eWog2Qmy5YtY/HixfTp06fufg2dFhIRh0bE/IhYGBFntrH+xIh4KCKaIuLuiNizbO8dEa+W7U0RcWkj65QkSWr22muv0b17d4P1u1xE0L1797X+C0bDRq4jogtwCTASWAzMjIipmTmvZrMrM/PScvvRwEXAoeW6xzNzUKPqkyRJWh2DtWDd3geNHLneD1iYmU9k5hvAZGBM7QaZ+VLN4vuAbGA9kiRJncIzzzzDuHHj6Nu3L4MHD+bwww/nscce6+iyVmv69Oncc889a9xu6NChAIwdO5alS5e2tHfp0oVBgwa1PBYtWsT06dPZZpttWtpGjBgBwOuvv87RRx9Nv3792H///Vm0aFHLfr73ve/Rr18/dt99d26++eaW9ptuuondd9+dfv36cd5557W0P/nkk+y///7069ePo48+mjfeeGN9T0VD51z3BJ6qWV4M7N96o4g4GTgd2AIYXrOqT0T8AXgJ+Hpm3tXAWiVJkto2alS1+7vhhnZXZyZjx45l/PjxTJ48GYA5c+bw7LPP8qEPfajaWioyffp03v/+9/PRj350tdssXLiQfv36kZk8/fTT7LTTTi3r3vOe99DU1PSO7RctWsSwYcP47W9/+472yy+/nG233ZaFCxcyefJkvvKVr3D11Vczb948Jk+ezNy5c3n66acZMWJEyweSk08+md/97nf06tWLfffdl9GjR7Pnnnvyla98hdNOO41x48Zx4okncvnll3PSSSet17no8FvxZeYlmdkX+Arw9bJ5KbBLZn6YInhfGRFbt+4bESdExKyImPX8889vuKIlSZIa5I477mDzzTfnxBNPbGnbZ599GDZsGJnJGWecwV577cXAgQO5+uqrgSLcHnTQQYwZM4bddtuNM888k1/+8pfst99+DBw4kMcffxyACRMmcNJJJ3HAAQew2267MX36dL7whS+wxx57MGHChJbj3XLLLQwdOpSPfOQjHHnkkfzlL38Bim/E/uY3v8lHPvIRBg4cyKOPPsqiRYu49NJLufjiixk0aBB33fXO8dBXX32VQYMGMXz4cKZPn84ee+zBggULGDRo0CqBuh7XX38948ePB+CII47gtttuIzO5/vrrGTduHFtuuSV9+vShX79+zJgxgxkzZtCvXz922203tthiC8aNG8f1119PZnL77bdzxBFHADB+/Hiuu+66ta6ntUaG6yXAzjXLvcq21ZkMfBYgM1/PzGXl89nA48AqH9Uy87LMHJKZQ3r0aPPr3SVJkjqVhx9+mMGDB7e57je/+Q1NTU3MmTOHW2+9lTPOOKNlesWcOXO49NJLeeSRR/j5z3/OY489xowZM/jiF7/ID3/4w5Z9rFixgnvvvZeLL76Y0aNHc9pppzF37lweeughmpqaeOGFF/jud7/LrbfeygMPPMCQIUO46KKLWvpvv/32PPDAA5x00kl8//vfp3fv3px44omcdtppNDU1MWzYsHfU3DwqPWrUKK677jrOOussvvOd79DU1MSgQYOAvwXwQYMGMXbs2Ja+d911V0v7ueeeC8CSJUvYeeciYnbt2pVtttmGZcuWvaMdoFevXixZsmS17cuWLeMDH/gAXbt2fUf7+mrktJCZQP+I6EMRqscBx9ZuEBH9M3NBufhpYEHZ3gNYnplvRcRuQH/giQbWKkmStNG7++67OeaYY+jSpQs77LADBx10EDNnzmTrrbdm3333bZlq0bdvXw4++GAABg4cyB133NGyj1GjRhERDBw4kB122IGBAwcCMGDAABYtWsTixYuZN28eH/vYxwB44403WuZKA3zuc58DYPDgwfzmN7+pu/aHHnqIAQMGcOWVV74jQEPb00KANqeFbOwaFq4zc2VEnALcDHQBrsjMuRFxDjArM6cCp0TECOBNYAUwvuz+ceCciHgTeBs4MTOXN6pWSZKkjcWAAQOYMmXKWvfbcsstW55vttlmLcubbbYZK1euXGW72m1qt+vSpQsjR47kqquuavc4Xbp0ecd+V+ecc87hmmuu4fHHH+eAAw7giSee4JZbbuHQQw/lwgsvXOvX2bNnT5566il69erFypUrefHFF+nevXtLe7PFixfTs2dPgDbbu3fvzp///GdWrlxJ165d37H9+mjol8hk5jRgWqu2s2ue/8tq+l0DXNPI2jq1NVwIUamqL+KQJEntGj58OF/96le57LLLOOGEEwB48MEHefHFFxk2bBg/+clPGD9+PMuXL+fOO+/kwgsv5NFHH63s+AcccAAnn3xyywWIr7zyCkuWLGn3YsqtttqKl156qc11Z599NocddhiTJk3i+9//PiNGjFhlXvbaGD16NBMnTmTo0KFMmTKF4cOHExGMHj2aY489ltNPP52nn36aBQsWsN9++5GZLFiwgCeffJKePXsyefJkrrzySiKCT37yk0yZMoVx48YxceJExowZs+YC1qDDL2iUJEnS30QE1157Lbfeeit9+/ZlwIABnHXWWey4446MHTuWvffem3322Yfhw4dzwQUXsOOOO1Z6/B49evCzn/2MY445hr333puhQ4euMbyPGjWKa6+9ts0LGgF+//vfM2zYMGbMmMEBBxywXvUdf/zxLFu2jH79+nHRRRe13FpvwIABHHXUUey5554ceuihXHLJJXTp0oWuXbvyox/9iEMOOYQ99tiDo446igEDBgBw/vnnc9FFF9GvXz+WLVvG8ccfv161AUTmpnFr6SFDhuSsWbM6uowNw5FrSZIa5pFHHmGPPfbo6DK0kWjr/RARszNzSFvbO3ItSZIkVcRwLUmSJFXEcC1JkiRVxHAtSZIkVcRwLUmSJFXEcC1JkiRVxHAtSZK0kXnmmWcYN24cffv2ZfDgwRx++OE89thjdfefMGHCOn3L4yuvvMKIESMAOPDAA1u+gXHRokW85z3vYdCgQS2PN954g5/97Gf06NGjpe24444DYPny5YwcOZL+/fszcuRIVqxYAUBmcuqpp9KvXz/23ntvHnjggZZjT5w4kf79+9O/f38mTpzY0j579mwGDhxIv379OPXUU9nYbyPd0G9olCRJ6vSq/n6JNXyHRGYyduxYxo8fz+TJkwGYM2cOzz77bLvfkliFe++9l6FDh7JixQre97730bXr36Ji3759aWpqWqXP0UcfzY9+9KN3tJ133nl86lOf4swzz+S8887jvPPO4/zzz+fGG29kwYIFLFiwgPvvv5+TTjqJ+++/n+XLl/Ptb3+bWbNmEREMHjyY0aNHs+2223LSSSfx3//93+y///4cfvjh3HTTTRx22GENPQ/rw5FrSZKkjcgdd9zB5ptvzoknntjSts8++zBs2DAykzPOOIO99tqLgQMHcvXVVwNFID/llFPYfffdGTFiBM8991xL39mzZ3PQQQcxePBgDjnkEJYuXbrKMR9//HEGDRrE5z//ea688koGDx7MnDlzGDRo0Dv2Va/rr7+e8ePHAzB+/Hiuu+66lvbjjjuOiOCAAw7gz3/+M0uXLuXmm29m5MiRbLfddmy77baMHDmSm266iaVLl/LSSy9xwAEHEBEcd9xxLfvaWBmuJUmSNiIPP/wwgwcPbnPdb37zG5qampgzZw633norZ5xxBkuXLuXaa69l/vz5zJs3j0mTJnHPPfcA8Oabb/KlL32JKVOmMHv2bL7whS/wta99bZX9No9KDx48mBkzZjB+/Hguv/xympqa+Lu/+zvgbwF80KBBnHzyyS19r7766pb2n/70pwA8++yz7LTTTgDsuOOOPPvsswAsWbKEnXfeuaVvr169WLJkSbvtvXr1WqV9Y+a0EEmSpE7i7rvv5phjjqFLly7ssMMOHHTQQcycOZM777yzpf2DH/wgw4cPB2D+/Pk8/PDDjBw5EoC33nqrJfS25bnnnqN79+48+OCDHH/88e9YtzbTQmpFBBGxDq+2c3LkWpIkaSMyYMAAZs+eXcm+MpMBAwbQ1NREU1MTDz30ELfccssq25144onstddeLFiwgEGDBnHTTTfxmc98hosvvnidjrvDDju0TD9ZunRpy+h3z549eeqpp1q2W7x4MT179my3ffHixau0b8wM15IkSRuR4cOH8/rrr3PZZZe1tD344IPcddddDBs2jKuvvpq33nqL559/njvvvJP99tuPj3/84y3tS5cu5Y477gBg99135/nnn+fee+8Fimkic+fOXeWYl156Kd/85jf5xje+wXXXXcenP/1pmpqaOO2009bpNYwePbrljh8TJ05kzJgxLe2TJk0iM7nvvvvYZptt2GmnnTjkkEO45ZZbWLFiBStWrOCWW27hkEMOYaeddmLrrbfmvvvuIzOZNGlSy742Vk4LkSRJ2ohEBNdeey1f/vKXOf/88+nWrRu9e/fmBz/4AQceeCD33nsv++yzDxHBBRdcwI477sjYsWO5/fbb2XPPPdlll10YOnQoAFtssQVTpkzh1FNP5cUXX2TlypV8+ctfZsCAAasc9/e//z3HHXccd911FwcddNB6vYYzzzyTo446issvv5xdd92VX/3qVwAcfvjhTJs2jX79+vHe9763ZY72dtttxze+8Q323XdfAM4++2y22247AH784x8zYcIEXn31VQ477LCN+k4hALGx3yuwXkOGDMlZs2Z1dBkbRtW3BGrPGm4XJEnSpuaRRx5hjz326OgytJFo6/0QEbMzc0hb2zstRJIkSaqI4VqSJEmqiOFakiRJqojhWpIkqZVN5Zo0rZ91eR8YriVJkmp069aNZcuWGbDf5TKTZcuW0a1bt7Xq5634JEmSavTq1YvFixfz/PPPd3Qp6mDdunV7x9ev18NwLUmSVGPzzTenT58+HV2GOimnhUiSJEkVMVxLkiRJFTFcS5IkSRUxXEuSJEkVMVxLkiRJFTFcS5IkSRUxXEuSJEkVMVxLkiRJFTFcS5IkSRUxXEuSJEkVMVxLkiRJFTFcS5IkSRVpaLiOiEMjYn5ELIyIM9tYf2JEPBQRTRFxd0TsWbPurLLf/Ig4pJF1SpIkSVVoWLiOiC7AJcBhwJ7AMbXhuXRlZg7MzEHABcBFZd89gXHAAOBQ4Mfl/iRJkqSNViNHrvcDFmbmE5n5BjAZGFO7QWa+VLP4PiDL52OAyZn5emY+CSws9ydJkiRttLo2cN89gadqlhcD+7feKCJOBk4HtgCG1/S9r1Xfno0pU5IkSapGh1/QmJmXZGZf4CvA19emb0ScEBGzImLW888/35gCJUmSpDo1MlwvAXauWe5Vtq3OZOCza9M3My/LzCGZOaRHjx7rV60kSZK0nhoZrmcC/SOiT0RsQXGB4tTaDSKif83ip4EF5fOpwLiI2DIi+gD9gRkNrFWSJElabw2bc52ZKyPiFOBmoAtwRWbOjYhzgFmZORU4JSJGAG8CK4DxZd+5EfErYB6wEjg5M99qVK2SJElSFRp5QSOZOQ2Y1qrt7Jrn/9JO33OBcxtXnSRJklStDr+gUZIkSdpUGK4lSZKkihiuJUmSpIoYriVJkqSKGK4lSZKkihiuJUmSpIoYriVJkqSKGK4lSZKkihiuJUmSpIoYriVJkqSKGK4lSZKkihiuJUmSpIoYriVJkqSKGK4lSZKkihiuJUmSpIoYriVJkqSKGK4lSZKkihiuJUmSpIoYriVJkqSKGK4lSZKkihiuJUmSpIoYriVJkqSKGK4lSZKkihiuJUmSpIoYriVJkqSKGK4lSZKkihiuJUmSpIoYriVJkqSKGK4lSZKkihiuJUmSpIoYriVJkqSKGK4lSZKkihiuJUmSpIoYriVJkqSKGK4lSZKkihiuJUmSpIo0NFxHxKERMT8iFkbEmW2sPz0i5kXEgxFxW0TsWrPurYhoKh9TG1mnJEmSVIWujdpxRHQBLgFGAouBmRExNTPn1Wz2B2BIZv41Ik4CLgCOLte9mpmDGlWfJEmSVLVGjlzvByzMzCcy8w1gMjCmdoPMvCMz/1ou3gf0amA9kiRJUkM1Mlz3BJ6qWV5ctq3O8cCNNcvdImJWRNwXEZ9tQH2SJElSpRo2LWRtRMTngSHAQTXNu2bmkojYDbg9Ih7KzMdb9TsBOAFgl1122WD1SpIkSW1p5Mj1EmDnmuVeZds7RMQI4GvA6Mx8vbk9M5eU/30CmA58uHXfzLwsM4dk5pAePXpUW70kSZK0lhoZrmcC/SOiT0RsAYwD3nHXj4j4MPATimD9XE37thGxZfl8e+BjQO2FkJIkSdJGp2HTQjJzZUScAtwMdAGuyMy5EXEOMCszpwIXAu8Hfh0RAH/KzNHAHsBPIuJtig8A57W6y4gkSZK00WnonOvMnAZMa9V2ds3zEavpdw8wsJG1SZIkSVXzGxolSZKkihiuJUmSpIoYriVJkqSKGK4lSZKkihiuJUmSpIoYriVJkqSKGK4lSZKkihiuJUmSpIoYriVJkqSKGK4lSZKkihiuJUmSpIoYriVJkqSKGK4lSZKkihiuJUmSpIoYriVJkqSKGK4lSZKkinStZ6OI+CjQu3b7zJzUoJokSZKkTmmN4Toifg70BZqAt8rmBAzXkiRJUo16Rq6HAHtmZja6GEmSJKkzq2fO9cPAjo0uRJIkSers6hm53h6YFxEzgNebGzNzdMOqkiRJkjqhesL1txpdhCRJkrQpWGO4zszfR8QOwL5l04zMfK6xZUmSJEmdzxrnXEfEUcAM4EjgKOD+iDii0YVJkiRJnU0900K+BuzbPFodET2AW4EpjSxMkiRJ6mzquVvIZq2mgSyrs58kSZL0rlLPyPVNEXEzcFW5fDQwrXElSZIkSZ1TPRc0nhER/wB8rGy6LDOvbWxZkiRJUudTz8g1mXkNcE2Da5EkSZI6tdWG64i4OzMPjIiXgdqvPg8gM3PrhlcnSZIkdSKrDdeZeWD53602XDmSJElS51XPfa5/Xk+bJEmS9G5Xzy31BtQuRERXYHBjypEkSZI6r9WG64g4q5xvvXdEvFQ+XgaeBa7fYBVKkiRJncRqw3Vmfq+cb31hZm5dPrbKzO6ZedYGrFGSJEnqFOq5z/VZEdET2LV2+8y8s5GFSZIkSZ1NPRc0ngf8L/B14Izy8W/17DwiDo2I+RGxMCLObGP96RExLyIejIjbImLXmnXjI2JB+Rhf9yuSJEmSOkg9XyIzFtg9M19fmx1HRBfgEmAksBiYGRFTM3NezWZ/AIZk5l8j4iTgAuDoiNgO+CYwhOIe27PLvivWpgZJkiRpQ6rnbiFPAJuvw773AxZm5hOZ+QYwGRhTu0Fm3pGZfy0X7wN6lc8PAX6XmcvLQP074NB1qEGSJEnaYOoZuf4r0BQRtwEto9eZeeoa+vUEnqpZXgzs3872xwM3ttO3Zx21SpIkSR2mnnA9tXw0TER8nmIKyEFr2e8E4ASAXXbZpQGVSZIkSfWr524hEyPiPcAumTl/Lfa9BNi5ZrlX2fYOETEC+BpwUM287iXAJ1r1nd5GbZcBlwEMGTIk16I2SZIkqXL13C1kFNAE3FQuD4qIekayZwL9I6JPRGwBjKPVCHhEfBj4CTA6M5+rWXUzcHBEbBsR2wIHl22SJEnSRqueCxq/RXFx4p8BMrMJ2G1NnTJzJXAKRSh+BPhVZs6NiHMiYnS52YXA+4FfR0RTc2jPzOXAdygC+kzgnLJNkiRJ2mjVM+f6zcx8MSJq296uZ+eZOQ2Y1qrt7JrnI9rpewVwRT3HkSRJkjYG9YTruRFxLNAlIvoDpwL3NLYsSZIkqfOpZ1rIl4ABFLfhuxJ4EfiXRhYlSZIkdUb1jFx/OjO/RnFHDwAi4kjg1w2rSpIkSeqE6hm5PqvONkmSJOldbbUj1xFxGHA40DMi/qtm1dbAykYXJkmSJHU27U0LeRqYBYwGZte0vwyc1siiJEmSpM5oteE6M+cAcyJih8ycWLsuIv4F+M9GFydJkiR1JvXMuR7XRtuEiuuQJEmSOr325lwfAxwL9Gn1dedbA35boiRJktRKe3Ou7wGWAtsD/1HT/jIwp5FFSZIkSZ1Re3Ou/wj8ERja3BYR7wM+B3wH+HTDq5MkSZI6kTXOuY6ILSJibET8mmIkezhwacMrkyRJkjqZ9uZcHwwcAxwM3AFMAvbNzH/eQLVJkiRJnUp7I9c3AbsBB2bm5zPzBuDtDVOWJEmS1Pm0d0HjRyhuw3drRDwBTAa6bJCq9K4x6qpRG/R4NxxzwwY9niRJendZ7ch1ZjZl5pmZ2Rf4JjAI2DwiboyIEzZUgZIkSVJnUc+XyJCZ92Tml4BewMXAAQ2tSpIkSeqE2psWsorMfBu4pXxIkiRJqlHXyLUkSZKkNVttuI6IPhuyEEmSJKmza2/kegpARNy2gWqRJEmSOrX25lxvFhFfBT4UEae3XpmZFzWuLEmSJKnzaW/kehzwFkUA36qNhyRJkqQaqx25zsz5wPkR8WBm3rgBa5IkSZI6pXruFnJPRFwUEbPKx39ExDYNr0ySJEnqZOoJ11cALwNHlY+XgJ82sihJkiSpM6rnS2T6ZuY/1Cx/OyKaGlSPJEmS1GnVM3L9akQc2LwQER8DXm1cSZIkSVLnVM/I9YnApJp51iuA8Y0rSZIkSeqc1hiuM3MOsE9EbF0uv9TwqiRJkqROqJ6Ra8BQLUmSJK1JPXOuJUmSJNXBcC1JkiRVZI3TQiKiC/BpoHft9pl5UePKkiRJkjqfeuZc3wC8BjwEvN3YciRJkqTOq55w3Ssz9254JZIkSVInV8+c6xsj4uB12XlEHBoR8yNiYUSc2cb6j0fEAxGxMiKOaLXurYhoKh9T1+X4kiRJ0oZUz8j1fcC1EbEZ8CYQQGbm1u11KudqXwKMBBYDMyNiambOq9nsT8AE4N/a2MWrmTmojvokSZKkjUI94foiYCjwUGbmWux7P2BhZj4BEBGTgTFAS7jOzEXlOudyS5IkqdOrZ1rIU8DDaxmsAXqWfZstLtvq1S0iZkXEfRHx2bU8tiRJkrTB1TNy/QQwPSJuBF5vbtwAt+LbNTOXRMRuwO0R8VBmPl67QUScAJwAsMsuuzS4HEmSJKl99YxcPwncBmwBbFXzWJMlwM41y73Ktrpk5pLyv08A04EPt7HNZZk5JDOH9OjRo95dS5IkSQ2xxpHrzPz2Ou57JtA/IvpQhOpxwLH1dIyIbYG/ZubrEbE98DHggnWsQ5IkSdog6vmGxjuAVeZbZ+bw9vpl5sqIOAW4GegCXJGZcyPiHGBWZk6NiH2Ba4FtgVER8e3MHADsAfykvNBxM+C8VncZkSRJkjY69cy5rr1NXjfgH4CV9ew8M6cB01q1nV3zfCbFdJHW/e4BBtZzDEmSJGljUc+0kNmtmv43ImY0qB5JkiSp06pnWsh2NYubAYOBbRpWkSRJktRJ1TMtZDbFnOugmA7yJHB8I4uSJEmSOqN6poX02RCFSJIkSZ3dau9zHRH7RsSONcvHRcT1EfFfraaKSJIkSaL9L5H5CfAGQER8HDgPmAS8CFzW+NIkSZKkzqW9aSFdMnN5+fxo4LLMvAa4JiKaGl6ZJEmS1Mm0N3LdJSKaw/engNtr1tVzIaQkSZL0rtJeSL4K+H1EvAC8CtwFEBH9KKaGSJIkSaqx2nCdmedGxG3ATsAtmdn8FeibAV/aEMVJkiRJnUm70zsy87422h5rXDmSJElS59XenGtJkiRJa8FwLUmSJFXEcC1JkiRVxHAtSZIkVcRwLUmSJFXEcC1JkiRVxG9alCRJUiVu4IYNerxRjNqgx6uHI9eSJElSRQzXkiRJUkUM15IkSVJFDNeSJElSRQzXkiRJUkUM15IkSVJFDNeSJElSRQzXkiRJUkUM15IkSVJFDNeSJElSRQzXkiRJUkUM15IkSVJFDNeSJElSRQzXkiRJUkUM15IkSVJFDNeSJElSRQzXkiRJUkUM15IkSVJFGhquI+LQiJgfEQsj4sw21n88Ih6IiJURcUSrdeMjYkH5GN/IOiVJkqQqNCxcR0QX4BLgMGBP4JiI2LPVZn8CJgBXtuq7HfBNYH9gP+CbEbFto2qVJEmSqtC1gfveD1iYmU8ARMRkYAwwr3mDzFxUrnu7Vd9DgN9l5vJy/e+AQ4GrGlivJGkNrho1aoMe75gbbtigx5Ok9dXIaSE9gadqlheXbY3uK0mSJHWITn1BY0ScEBGzImLW888/39HlSJIk6V2ukeF6CbBzzXKvsq2yvpl5WWYOycwhPXr0WOdCJUmSpCo0MlzPBPpHRJ+I2AIYB0yts+/NwMERsW15IePBZZskSZK00WpYuM7MlcApFKH4EeBXmTk3Is6JiNEAEbFvRCwGjgR+EhFzy77Lge9QBPSZwDnNFzdKkiRJG6tG3i2EzJwGTGvVdnbN85kUUz7a6nsFcEUj65MkSZKq1KkvaJQkSZI2JoZrSZIkqSKGa0mSJKkihmtJkiSpIoZrSZIkqSKGa0mSJKkihmtJkiSpIoZrSZIkqSKGa0mSJKkihmtJkiSpIoZrSZIkqSKGa0mSJKkihmtJkiSpIoZrSZIkqSKGa0mSJKkiXTu6AEmSVL0bbtiwxxs1asMeT9pYOXItSZIkVcRwLUmSJFXEcC1JkiRVxHAtSZIkVcRwLUmSJFXEcC1JkiRVxHAtSZIkVcRwLUmSJFXEcC1JkiRVxHAtSZIkVcRwLUmSJFXEcC1JkiRVxHAtSZIkVcRwLUmSJFXEcC1JkiRVxHAtSZIkVcRwLUmSJFXEcC1JkiRVxHAtSZIkVcRwLUmSJFWkoeE6Ig6NiPkRsTAizmxj/ZYRcXW5/v6I6F22946IVyOiqXxc2sg6JUmSpCp0bdSOI6ILcAkwElgMzIyIqZk5r2az44EVmdkvIsYB5wNHl+sez8xBjapPkiRJqlojR673AxZm5hOZ+QYwGRjTapsxwMTy+RTgUxERDaxJkiRJaphGhuuewFM1y4vLtja3ycyVwItA93Jdn4j4Q0T8PiKGNbBOSZIkqRINmxaynpYCu2TmsogYDFwXEQMy86XajSLiBOAEgF122aUDypQkSZL+ppEj10uAnWuWe5VtbW4TEV2BbYBlmfl6Zi4DyMzZwOPAh1ofIDMvy8whmTmkR48eDXgJkiRJUv0aGa5nAv0jok9EbAGMA6a22mYqML58fgRwe2ZmRPQoL4gkInYD+gNPNLBWSZIkab01bFpIZq6MiFOAm4EuwBWZOTcizgFmZeZU4HLg5xGxEFhOEcABPg6cExFvAm8DJ2bm8kbVKkmSJFWhoXOuM3MaMK1V29k1z18Djmyj3zXANY2sTZIkSaqa39AoSZIkVcRwLUmSJFXEcC1JkiRVxHAtSZIkVcRwLUmSJFXEcC1JkiRVxHAtSZIkVcRwLUmSJFXEcC1JkiRVxHAtSZIkVcRwLUmSJFXEcC1JkiRVxHAtSZIkVcRwLUmSJFXEcC1JkiRVxHAtSZIkVcRwLUmSJFWka0cXIEmbvBs24LFGbcBjSZJWYbiWVJ/FGzAh9jIhSpI6J8O1JElSjQ35xybwD06bGudcS5IkSRUxXEuSJEkVMVxLkiRJFTFcS5IkSRUxXEuSJEkVMVxLkiRJFTFcS5IkSRUxXEuSJEkVMVxLkiRJFTFcS5IkSRUxXEuSJEkVMVxLkiRJFTFcS5IkSRUxXEuSJEkVMVxLkiRJFTFcS5IkSRVpaLiOiEMjYn5ELIyIM9tYv2VEXF2uvz8ietesO6tsnx8RhzSyTkmSJKkKDQvXEdEFuAQ4DNgTOCYi9my12fHAiszsB1wMnF/23RMYBwwADgV+XO5PkiRJ2mg1cuR6P2BhZj6RmW8Ak4ExrbYZA0wsn08BPhURUbZPzszXM/NJYGG5P0mSJGmj1chw3RN4qmZ5cdnW5jaZuRJ4EeheZ19JkiRpo9K1owtYHxFxAnBCufiXiJjfkfVsQNsDL3R0EZ1RHBueu3XnuVt3nrt1dGz4O7sePHfrznO37t4t527X1a1oZLheAuxcs9yrbGtrm8UR0RXYBlhWZ18y8zLgsgpr7hQiYlZmDunoOjojz92689ytO8/duvPcrTvP3brz3K07z11jp4XMBPpHRJ+I2ILiAsWprbaZCowvnx8B3J6ZWbaPK+8m0gfoD8xoYK2SJEnSemvYyHVmroyIU4CbgS7AFZk5NyLOAWZl5lTgcuDnEbEQWE4RwCm3+xUwD1gJnJyZbzWqVkmSJKkKDZ1znZnTgGmt2s6uef4acORq+p4LnNvI+jqxd91UmAp57tad527dee7Wnedu3Xnu1p3nbt29689dFLMwJEmSJK0vv/5ckiRJqojhWpIkSaqI4VqSJEmqiOFakiRJqojhWpIkSaqI4VqSOlhE7BgRkyPi8YiYHRHTIuJD7WzfOyIeXs9j7hARV0bEE+Ux742IseuzT0mS4VqSOlREBHAtMD0z+2bmYOAsYIcKj9G11XIA1wF3ZuZu5THHAb3W1FeS1D7DtSR1rE8Cb2bmpc0NmTknM++KwoUR8XBEPBQRR7fuHBHdIuKn5fo/RMQny/YJETE1Im4HbmvVbTjwRqtj/jEzf9hW34jYLiKui4gHI+K+iNi73O5bEfFvNbU8XI6q946IRyPilxHxSERMiYj3ltucFxHzyn19v7KzKEkbCUckJKlj7QXMXs26zwGDgH2A7YGZEXFnq21OBjIzB0bE3wO31Ewp+Qiwd2Yub9VnAPDAGupq6RsRPwT+kJmfjYjhwKSyrvbsDhyfmf8bEVcA/zcifgqMBf4+MzMiPrCGfUhSp+PItSRtvA4ErsrMtzLzWeD3wL5tbPMLgMx8FPgj0Byuf9dGsF5FRFwSEXMiYmZNc23fA4Gfl8e4HegeEVuvYbdPZeb/ls9/Ue7jReA14PKI+Bzw1zXVJkmdjeFakjrWXGBwg/b9SjvH/EjzQmaeDHwK6FFH31oreef/R7rVPM9W22ZmrgT2A6YAnwFuquMYktSpGK4lqWPdDmwZESc0N0TE3hExDLgLODoiukRED+DjwIxW/e8C/rHs9yFgF2B+HcfsFhEn1bS9t53ta4/xCeCFzHwJWEQZ0iPiI0Cfmj67RMTQ8vmxwN0R8X5gm8ycBpxGMd1FkjYphmtJ6kCZmRTzkEeUt+KbC3wPeIbiLiIPAnMoAvG/Z+YzrXbxY2CziHgIuBqYkJmv13HMzwIHRcSTETEDmAh8ZTVdvgUMjogHgfOA8WX7NcB2Zc2nAI/V9JkPnBwRjwDbAv8fsBXw23I/dwOnt1enJHVGUfwbK0lSNSKiN/DbzNyro2uRpA3NkWtJkiSpIo5cS5IkSRVx5FqSJEmqiOFakiRJqojhWpIkSaqI4VqSJEmqiOFakiRJqojhWpIkSarI/w/DVLO47ASP9AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Calculate sum of attention by color groups\n",
    "color_groups_comment = {}\n",
    "color_groups_code = {}\n",
    "\n",
    "# Group attentions by color for comments\n",
    "for idx, color in color_map_comment.items():\n",
    "    if color not in color_groups_comment:\n",
    "        color_groups_comment[color] = []\n",
    "    color_groups_comment[color].append(array[idx])\n",
    "\n",
    "# Group attentions by color for code\n",
    "for idx, color in color_map_code.items():\n",
    "    if color not in color_groups_code:\n",
    "        color_groups_code[color] = []\n",
    "    color_groups_code[color].append(code_attention_feature[idx])\n",
    "\n",
    "# Calculate sums for each color group\n",
    "comment_color_sums = {color: np.sum(attns) for color, attns in color_groups_comment.items()}\n",
    "code_color_sums = {color: np.sum(attns) for color, attns in color_groups_code.items()}\n",
    "\n",
    "# Print comparison with color blocks\n",
    "print(\"Attention sums by color group:\")\n",
    "print(\"\\nComment:\")\n",
    "for color, sum_val in comment_color_sums.items():\n",
    "    print(f\"\\033[48;2;{int(color[1:3],16)};{int(color[3:5],16)};{int(color[5:7],16)}m  \\033[0m {color}: {sum_val:.4f}\")\n",
    "    \n",
    "print(\"\\nCode:\")\n",
    "for color, sum_val in code_color_sums.items():\n",
    "    print(f\"\\033[48;2;{int(color[1:3],16)};{int(color[3:5],16)};{int(color[5:7],16)}m  \\033[0m {color}: {sum_val:.4f}\")\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "colors = list(set(color_map_comment.values()) | set(color_map_code.values()))\n",
    "x = np.arange(len(colors))\n",
    "width = 0.35\n",
    "\n",
    "comment_sums = [comment_color_sums.get(c, 0) for c in colors]\n",
    "code_sums = [code_color_sums.get(c, 0) for c in colors]\n",
    "\n",
    "# Use the same colors for both comment and code bars\n",
    "for i, (c_sum, cd_sum, color) in enumerate(zip(comment_sums, code_sums, colors)):\n",
    "    plt.bar(i - width/2, c_sum, width, color=color, alpha=0.7, label=f'Comment {color}' if i==0 else \"\")\n",
    "    plt.bar(i + width/2, cd_sum, width, color=color, alpha=0.3, label=f'Code {color}' if i==0 else \"\")\n",
    "\n",
    "plt.xlabel('Color Groups')\n",
    "plt.ylabel('Sum of Attention')\n",
    "plt.title('Comparison of Attention Sums by Color Group')\n",
    "\n",
    "# Create colored rectangles for x-axis labels\n",
    "ax = plt.gca()\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([''] * len(colors))  # Clear text labels\n",
    "for i, color in enumerate(colors):\n",
    "    ax.add_patch(plt.Rectangle((i-0.2, -0.1), 0.4, 0.05, color=color, transform=ax.transData))\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish initialization...\n",
      "Thu Feb 13 11:35:06 2025 Building RP forest with 5 trees\n",
      "Thu Feb 13 11:35:07 2025 NN descent for 6 iterations\n",
      "\t 1  /  6\n",
      "\t 2  /  6\n",
      "\tStopping threshold met -- exiting after 2 iterations\n",
      "complex-construct: 0.4079780578613281\n",
      "====================\n",
      "epoch:1\n",
      "===================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "umap:7.3029\trecon_l:0.2363\tnew_loss:7.3029\tloss:7.5393\n",
      "====================\n",
      "epoch:2\n",
      "===================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "umap:1.4612\trecon_l:0.2297\tnew_loss:1.4612\tloss:1.6909\n",
      "====================\n",
      "epoch:3\n",
      "===================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "umap:0.6552\trecon_l:0.2268\tnew_loss:0.6552\tloss:0.8820\n",
      "====================\n",
      "epoch:4\n",
      "===================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "umap:0.8341\trecon_l:0.6285\tnew_loss:0.8341\tloss:1.4626\n",
      "====================\n",
      "epoch:5\n",
      "===================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "umap:0.8741\trecon_l:0.2089\tnew_loss:0.8741\tloss:1.0830\n",
      "====================\n",
      "epoch:6\n",
      "===================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "umap:0.8604\trecon_l:0.1871\tnew_loss:0.8604\tloss:1.0474\n",
      "====================\n",
      "epoch:7\n",
      "===================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "umap:0.8452\trecon_l:0.1756\tnew_loss:0.8452\tloss:1.0208\n",
      "====================\n",
      "epoch:8\n",
      "===================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "umap:0.8679\trecon_l:0.1691\tnew_loss:0.8679\tloss:1.0370\n",
      "====================\n",
      "epoch:9\n",
      "===================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "umap:0.8447\trecon_l:0.1666\tnew_loss:0.8447\tloss:1.0113\n",
      "====================\n",
      "epoch:10\n",
      "===================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "umap:0.7950\trecon_l:0.1656\tnew_loss:0.7950\tloss:0.9606\n",
      "Time spend: 13.40 for training vis model...\n",
      "training: 13.399554014205933\n",
      "Successfully save visualization model...\n",
      "Finish epoch 1...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\"\n",
    "import time\n",
    "\n",
    "# # 读取高维向量 (num, 768)\n",
    "# input_path = '/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp_2/Model/Epoch_1/train_data.npy'\n",
    "# data = np.load(input_path)\n",
    "\n",
    "ENCODER_DIMS = [768,256,256,256,256,2]\n",
    "DECODER_DIMS = [2,256,256,256,256,768]\n",
    "\n",
    "CONTENT_PATH = '/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp_2'\n",
    "EPOCH_START = 1\n",
    "EPOCH_END = 1\n",
    "EPOCH_PERIOD = 1\n",
    "B_N_EPOCHS = 0\n",
    "N_NEIGHBORS = 5\n",
    "VIS_MODEL_NAME = 'dvi_aa'\n",
    "LAMBDA1 = 1\n",
    "S_N_EPOCHS = 5\n",
    "PATIENT = 3\n",
    "MAX_EPOCH = 10\n",
    "GPU_ID = 3\n",
    "DEVICE = torch.device(\"cuda:{}\".format(GPU_ID) if torch.cuda.is_available() else \"cpu\")\n",
    "net = \"Model\"\n",
    "CLASSES = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\"]\n",
    "\n",
    "# Define data_provider\n",
    "data_provider = NormalDataProvider(CONTENT_PATH, net, EPOCH_START, EPOCH_END, EPOCH_PERIOD, device=DEVICE, epoch_name='Epoch',classes=CLASSES,verbose=1)\n",
    "\n",
    "# Define visualization models\n",
    "model = VisModel(ENCODER_DIMS, DECODER_DIMS)\n",
    "\n",
    "# Define Losses\n",
    "negative_sample_rate = 5\n",
    "min_dist = .1\n",
    "_a, _b = find_ab_params(1.0, min_dist)\n",
    "\n",
    "umap_loss_fn = UmapLoss(negative_sample_rate, DEVICE, _a, _b, repulsion_strength=1.0)\n",
    "recon_loss_fn = ReconstructionLoss(beta=1.0)\n",
    "single_loss_fn = SingleVisLoss(umap_loss_fn, recon_loss_fn, lambd=1)\n",
    "# Define Projector\n",
    "projector = VISProjector(vis_model=model, content_path=CONTENT_PATH, vis_model_name=VIS_MODEL_NAME, device=DEVICE)\n",
    "\n",
    "prev_model = VisModel(ENCODER_DIMS, DECODER_DIMS)\n",
    "start_flag = 1\n",
    "\n",
    "for iteration in range(EPOCH_START, EPOCH_END+EPOCH_PERIOD, EPOCH_PERIOD):\n",
    "    # Define DVI Loss\n",
    "    if start_flag:\n",
    "        temporal_loss_fn = DummyTemporalLoss(DEVICE)\n",
    "        criterion = DVILoss(umap_loss_fn, recon_loss_fn, temporal_loss_fn, lambd1=1, lambd2=0.0,device=DEVICE)\n",
    "        start_flag = 0\n",
    "    else:\n",
    "        # TODO AL mode, redefine train_representation\n",
    "        prev_data = data_provider.train_representation(iteration-EPOCH_PERIOD)\n",
    "        prev_data = prev_data.reshape(prev_data.shape[0],prev_data.shape[1])\n",
    "        curr_data = data_provider.train_representation(iteration)\n",
    "        curr_data = curr_data.reshape(curr_data.shape[0],curr_data.shape[1])\n",
    "        print(prev_data.shape, curr_data.shape)\n",
    "        t_1= time.time()\n",
    "        npr = torch.tensor(find_neighbor_preserving_rate(prev_data, curr_data, N_NEIGHBORS)).to(DEVICE)\n",
    "        t_2= time.time()\n",
    "     \n",
    "        temporal_loss_fn = TemporalLoss(w_prev, DEVICE)\n",
    "        criterion = DVILoss(umap_loss_fn, recon_loss_fn, temporal_loss_fn, lambd1=1, lambd2=0.1*npr,device=DEVICE)\n",
    "\n",
    "    # Define training parameters\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=.01, weight_decay=1e-5)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=.1)\n",
    "    # Define Edge dataset\n",
    "\n",
    "    t0 = time.time()\n",
    "    ##### construct the spitial complex\n",
    "    spatial_cons = SingleEpochTextSpatialEdgeConstructor(data_provider, iteration, S_N_EPOCHS, B_N_EPOCHS, N_NEIGHBORS, net)\n",
    "    edge_to, edge_from, probs, feature_vectors, attention = spatial_cons.construct()\n",
    "    t1 = time.time()\n",
    "\n",
    "    print('complex-construct:', t1-t0)\n",
    "\n",
    "    probs = probs / (probs.max()+1e-3)\n",
    "    eliminate_zeros = probs> 1e-3    #1e-3\n",
    "    edge_to = edge_to[eliminate_zeros]\n",
    "    edge_from = edge_from[eliminate_zeros]#     probs = probs[eliminate_zeros]\n",
    "    \n",
    "    labels_non_boundary = np.zeros(len(edge_to))\n",
    "\n",
    "    # pred_list = data_provider.get_pred(iteration, feature_vectors)\n",
    "    pred_list = np.zeros(feature_vectors.shape)\n",
    "    dataset = VisDataHandler(edge_to, edge_from, feature_vectors, attention, probs,pred_list)\n",
    "\n",
    "    n_samples = int(np.sum(S_N_EPOCHS * probs) // 1)\n",
    "    # chose sampler based on the number of dataset\n",
    "    if len(edge_to) > pow(2,24):\n",
    "        sampler = CustomWeightedRandomSampler(probs, n_samples, replacement=True)\n",
    "    else:\n",
    "        sampler = WeightedRandomSampler(probs, n_samples, replacement=True)\n",
    "    edge_loader = DataLoader(dataset, batch_size=2000, sampler=sampler, num_workers=8, prefetch_factor=10)\n",
    "\n",
    "    ########################################################################################################################\n",
    "    #                                                       TRAIN                                                          #\n",
    "    ########################################################################################################################\n",
    "\n",
    "    trainer = BaseTextTrainer(model, criterion, optimizer, lr_scheduler, edge_loader=edge_loader, DEVICE=DEVICE)\n",
    "\n",
    "    t2=time.time()\n",
    "    trainer.train(PATIENT, MAX_EPOCH, data_provider,iteration)\n",
    "    t3 = time.time()\n",
    "    print('training:', t3-t2)\n",
    "    # save result\n",
    "    save_dir = data_provider.model_path\n",
    "    trainer.record_time(save_dir, \"time_{}\".format(VIS_MODEL_NAME), \"complex_construction\", str(iteration), t1-t0)\n",
    "    trainer.record_time(save_dir, \"time_{}\".format(VIS_MODEL_NAME), \"training\", str(iteration), t3-t2)\n",
    "    save_dir = os.path.join(data_provider.model_path, \"Epoch_{}\".format(iteration))\n",
    "    trainer.save(save_dir=save_dir, file_name=\"{}\".format(VIS_MODEL_NAME))\n",
    "\n",
    "    print(\"Finish epoch {}...\".format(iteration))\n",
    " \n",
    "    prev_model.load_state_dict(model.state_dict())\n",
    "    for param in prev_model.parameters():\n",
    "        param.requires_grad = False\n",
    "    w_prev = dict(prev_model.named_parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load the DVI visualization model for iteration 1\n",
      "x_min: -7.704728984832762, x_max: 70.87960472106934, y_min: -5.208684349060058, y_max: 37.396309280395506\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale saved to /home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp_2/Model/Epoch_1/scale.npy\n",
      "Embedding saved to /home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp_2/Model/Epoch_1/embedding.npy\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for iteration in range(EPOCH_START, EPOCH_END+EPOCH_PERIOD, EPOCH_PERIOD):\n",
    "    iter_data = data_provider.train_representation(iteration)\n",
    "    embedding = projector.batch_project(iteration, iter_data)\n",
    "    all_nodes_2d = embedding  # 使用你降维后的二维数据\n",
    "\n",
    "    x_min, y_min = np.min(all_nodes_2d, axis=0)\n",
    "    x_max, y_max = np.max(all_nodes_2d, axis=0)\n",
    "    # ebd_extent = ebd_max - ebd_min\n",
    "    x_extent = x_max - x_min\n",
    "    y_extent = y_max - y_min\n",
    "\n",
    "    x_min = x_min - 0.3 * x_extent\n",
    "    x_max = x_max + 0.3 * x_extent\n",
    "    y_min = y_min - 0.3 * y_extent\n",
    "    y_max = y_max + 0.3 * y_extent\n",
    "\n",
    "    # 打印结果\n",
    "    print(f\"x_min: {x_min}, x_max: {x_max}, y_min: {y_min}, y_max: {y_max}\")\n",
    "\n",
    "    # 将结果保存到指定文件夹\n",
    "    save_dir = os.path.join(data_provider.model_path, \"Epoch_{}\".format(iteration))\n",
    "    scale_path = os.path.join(save_dir, \"scale.npy\")\n",
    "    np.save(scale_path, [x_min, y_min, x_max, y_max])\n",
    "\n",
    "    # 保存embedding结果\n",
    "    embedding_path = os.path.join(save_dir, \"embedding.npy\") \n",
    "    np.save(embedding_path, embedding)\n",
    "\n",
    "    # 可视化 embedding 的二维散点图\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(embedding[:, 0], embedding[:, 1], s=5, cmap='Spectral', alpha=0.7)\n",
    "    plt.title('2D UMAP projection of the embeddings')\n",
    "    plt.xlabel('UMAP 1')\n",
    "    plt.ylabel('UMAP 2')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Scale saved to {scale_path}\")\n",
    "    print(f\"Embedding saved to {embedding_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 2):\n",
    "    source_file = f'/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp_2/Model/Epoch_{i}/embedding.npy'\n",
    "    destination_file = f'/home/yiming/cophi/training_dynamic/gcb_tokens_visactor_temp_2/visualize/DVI/projection/{i}.npy'\n",
    "    shutil.copyfile(source_file, destination_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visualizer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
